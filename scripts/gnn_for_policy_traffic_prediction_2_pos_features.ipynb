{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.transforms import LineGraph\n",
    "from shapely.geometry import LineString\n",
    "import gnn_io as gio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "Here we investigate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "num_epochs = 40\n",
    "batch_size = 20\n",
    "lr = 0.001\n",
    "project_name = 'with_pos_features'\n",
    "train_ratio = 0.8\n",
    "wandb.login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.nn import MLP, PointNetConv, fps, global_max_pool, radius\n",
    "\n",
    "# class SAModule(torch.nn.Module):\n",
    "#     def __init__(self, ratio, r, nn):\n",
    "#         super().__init__()\n",
    "#         self.ratio = ratio\n",
    "#         self.r = r\n",
    "#         self.conv = PointNetConv(nn, add_self_loops=False)\n",
    "\n",
    "#     def forward(self, x, pos, batch):\n",
    "#         idx = fps(pos, batch, ratio=self.ratio)\n",
    "#         row, col = radius(pos, pos[idx], self.r, batch, batch[idx], max_num_neighbors=64)\n",
    "#         edge_index = torch.stack([col, row], dim=0)\n",
    "#         x_dst = None if x is None else x[idx]\n",
    "#         x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
    "#         pos, batch = pos[idx], batch[idx]\n",
    "#         return x, pos, batch\n",
    "\n",
    "# class GlobalSAModule(torch.nn.Module):\n",
    "#     def __init__(self, nn):\n",
    "#         super().__init__()\n",
    "#         self.nn = nn\n",
    "\n",
    "#     def forward(self, x, pos, batch):\n",
    "#         x = self.nn(torch.cat([x, pos], dim=1))\n",
    "#         x = global_max_pool(x, batch)\n",
    "#         return x\n",
    "\n",
    "# class Net(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.sa_module = SAModule(0.5, 0.2, MLP([3, 64, 128]))\n",
    "#         self.global_sa_module = GlobalSAModule(MLP([128 + 3, 256, 512]))\n",
    "#         self.mlp = MLP([512, 256, 1], dropout=0.5, norm=None)\n",
    "\n",
    "#     def forward(self, data):\n",
    "#         x, pos, batch = data.x, data.pos, data.batch\n",
    "#         x, pos, batch = self.sa_module(x, pos, batch)\n",
    "#         x = self.global_sa_module(x, pos, batch)\n",
    "#         return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_cluster import knn_graph\n",
    "from torch_geometric.nn import global_max_pool\n",
    "from torch_geometric.nn import PointNetConv\n",
    "\n",
    "class GnnWithPos(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        local_MLP_1 = nn.Sequential(\n",
    "            nn.Linear(in_channels, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "        )\n",
    "        \n",
    "        global_MLP_1 = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.conv1 = PointNetConv(local_nn = local_MLP_1, global_nn = global_MLP_1)\n",
    "        \n",
    "        # local_MLP_2 = nn.Sequential(\n",
    "        #     nn.Linear(128, 32),\n",
    "        # )\n",
    "        \n",
    "        # global_MLP_2 = nn.Sequential(\n",
    "        #     nn.Linear(32, 64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(64, out_channels)\n",
    "        # )\n",
    "        # self.conv2 = PointNetConv(local_nn = local_MLP_2, global_nn = global_MLP_2)\n",
    "\n",
    "    def forward(self, x, pos, edge_index):\n",
    "        x = self.conv1(x=x, pos=pos, edge_index=edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.conv2(x=x, pos=pos, edge_index=edge_index)\n",
    "        # x = F.relu(x)\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of dictionaries\n",
    "data_dict_list = torch.load('../results/dataset_1pm_0-1382.pt')\n",
    "\n",
    "# Reconstruct the Data objects\n",
    "datalist = [Data(x=d['x'], edge_index=d['edge_index'], pos=d['pos'], y=d['y']) for d in data_dict_list]\n",
    "\n",
    "# Recreate the dataset\n",
    "dataset = gio.MyGeometricDataset(datalist)\n",
    "\n",
    "# Apply normalization to your dataset\n",
    "dataset_normalized = gio.normalize_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[31216, 1], edge_index=[2, 59135], y=[31216, 1], pos=[31216, 2], normalized_x=[31216, 1], normalized_pos=[31216, 2], normalized_y=[31216, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_normalized[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/MATSim/eqasim-java/ile_de_france/src/main/python/gnn/wandb/run-20240705_130813-vjjpua2a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/with_pos_features/runs/vjjpua2a' target=\"_blank\">genial-fog-16</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/with_pos_features' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/with_pos_features' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/with_pos_features</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/with_pos_features/runs/vjjpua2a' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/with_pos_features/runs/vjjpua2a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wandb.init(\n",
    "        project=project_name,\n",
    "        config={\n",
    "            \"epochs\": num_epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"lr\": lr,\n",
    "            # 'early_stopping_patience': 10,\n",
    "            # \"dropout\": 0.15,\n",
    "            })\n",
    "config = wandb.config\n",
    "\n",
    "model = GnnWithPos(3, 1).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fct = torch.nn.MSELoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset length: 1382\n",
      "Training subset length: 1100\n",
      "Total dataset length: 1382\n",
      "Validation subset length: 260\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "train_dl = gio.create_dataloader(dataset=dataset_normalized, is_train=True, batch_size=config.batch_size, train_ratio=train_ratio)\n",
    "valid_dl = gio.create_dataloader(dataset=dataset_normalized, is_train=False, batch_size=config.batch_size, train_ratio=train_ratio)\n",
    "n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "print(n_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[31216, 1], edge_index=[2, 59135], y=[31216, 1], pos=[31216, 2], normalized_x=[31216, 1], normalized_pos=[31216, 2], normalized_y=[31216, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dl.dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the model\n",
    "\n",
    "We first find a good model for one batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 0.006164898630231619\n",
      "epoch: 0, val_loss: 0.005560705008415075\n",
      "epoch: 1, train loss: 0.005566890817135572\n",
      "epoch: 1, val_loss: 0.005820847044770534\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 2, train loss: 0.0058210864663124084\n",
      "epoch: 2, val_loss: 0.005818090903071256\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 3, train loss: 0.005862414371222258\n",
      "epoch: 3, val_loss: 0.00564519025815221\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 4, train loss: 0.0057152011431753635\n",
      "epoch: 4, val_loss: 0.005556888555964598\n",
      "epoch: 5, train loss: 0.005566077772527933\n",
      "epoch: 5, val_loss: 0.005594104850808015\n",
      "EarlyStopping counter: 1 out of 10\n",
      "epoch: 6, train loss: 0.005610513035207987\n",
      "epoch: 6, val_loss: 0.0056577338837087154\n",
      "EarlyStopping counter: 2 out of 10\n",
      "epoch: 7, train loss: 0.005657061468809843\n",
      "epoch: 7, val_loss: 0.0056619365842869645\n",
      "EarlyStopping counter: 3 out of 10\n",
      "epoch: 8, train loss: 0.005642305128276348\n",
      "epoch: 8, val_loss: 0.005612973840190814\n",
      "EarlyStopping counter: 4 out of 10\n",
      "epoch: 9, train loss: 0.005609360057860613\n",
      "epoch: 9, val_loss: 0.005564109673007176\n",
      "EarlyStopping counter: 5 out of 10\n",
      "epoch: 10, train loss: 0.005637396592646837\n",
      "epoch: 10, val_loss: 0.005557620933709236\n",
      "EarlyStopping counter: 6 out of 10\n",
      "epoch: 11, train loss: 0.005576576106250286\n",
      "epoch: 11, val_loss: 0.005587463374607838\n",
      "EarlyStopping counter: 7 out of 10\n",
      "epoch: 12, train loss: 0.005602995865046978\n",
      "epoch: 12, val_loss: 0.005608731844963936\n",
      "EarlyStopping counter: 8 out of 10\n",
      "epoch: 13, train loss: 0.005600946955382824\n",
      "epoch: 13, val_loss: 0.005598695590518988\n",
      "EarlyStopping counter: 9 out of 10\n",
      "epoch: 14, train loss: 0.005623793229460716\n",
      "epoch: 14, val_loss: 0.005571784523244088\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa910f79bc9a437bbc933054fb7590e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.019 MB of 0.019 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_loss</td><td>▁██▃▁▂▄▄▂▁▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_loss</td><td>0.00557</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">genial-fog-16</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/with_pos_features/runs/vjjpua2a' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/with_pos_features/runs/vjjpua2a</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/with_pos_features' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/with_pos_features</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240705_130813-vjjpua2a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def validate_model(model, valid_dl, loss_func, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    num_batches = 0\n",
    "    with torch.inference_mode():\n",
    "        for idx, data in enumerate(valid_dl):\n",
    "            input_node_features, targets = data.normalized_x.to(device), data.normalized_y.to(device)\n",
    "            predicted = model(data.normalized_x, data.normalized_pos, data.edge_index)\n",
    "            val_loss += loss_func(predicted, targets).item()\n",
    "            num_batches += 1\n",
    "    return val_loss / num_batches if num_batches > 0 else 0\n",
    "\n",
    "\n",
    "early_stopping = gio.EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    data = next(iter(train_dl))\n",
    "    # for idx in range(len(train_dl)):\n",
    "        \n",
    "    # for idx, data in enumerate(train_dl):\n",
    "    input_node_features, targets = data.normalized_x.to(device), data.normalized_y.to(device)\n",
    "    predicted = model(data.normalized_x, data.normalized_pos, data.edge_index)\n",
    "    train_loss = loss_fct(predicted, targets)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    # wandb.log({\"train_loss\": train_loss.item(), \"epoch\": epoch, \"step\": idx})\n",
    "    print(f\"epoch: {epoch}, train loss: {train_loss.item()}\")\n",
    "        \n",
    "    val_loss = validate_model(model, valid_dl, loss_fct, device)\n",
    "    wandb.log({\"val_loss\": val_loss})\n",
    "    print(f\"epoch: {epoch}, val_loss: {val_loss}\")\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "    \n",
    "wandb.summary[\"val_loss\"] = val_loss\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([624320, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GnnWithPos(\n",
       "  (conv1): PointNetConv(local_nn=Sequential(\n",
       "    (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  ), global_nn=Sequential(\n",
       "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  ))\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
