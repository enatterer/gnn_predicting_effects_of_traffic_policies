{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "import help_functions as hf\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from gnn_architecture import MyGnn  # or whatever you need to import\n",
    "import help_functions as hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ABSTRACT -->\n",
    "\n",
    "THIS IS WORK IN PROGRESS! \n",
    "\n",
    "The goal of this script is to apply monte carlo dropout to the trained model and check how well it performs.\n",
    "\n",
    "Perspectively, one can also introduce more uncertainty methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to adapt\n",
    "\n",
    "run_path = '../../data/runs_01_2025/'\n",
    "point_net_conv_layer_structure_local_mlp = \"256\"\n",
    "point_net_conv_layer_structure_global_mlp = \"512\"\n",
    "gat_conv_layer_structure = \"128,256,512,256\" \n",
    "dropout = 0.3\n",
    "use_dropout = False \n",
    "predict_mode_stats = False\n",
    "in_channels = 5\n",
    "out_channels = 1 \n",
    "loss_fct = torch.nn.MSELoss()\n",
    "\n",
    "# The rest we can usually leave as is\n",
    "districts = gpd.read_file(\"../../data/visualisation/districts_paris.geojson\")\n",
    "pnc_l_string = point_net_conv_layer_structure_local_mlp.replace(',', '_')\n",
    "pnc_g_string = point_net_conv_layer_structure_global_mlp.replace(',', '_') \n",
    "gat_string = gat_conv_layer_structure.replace(',', '_')\n",
    "\n",
    "# unique_model_description = f\"pnc_local_[{pnc_l_string}]_\" + \\\n",
    "# f\"pnc_global_[{pnc_g_string}]_\" + \\\n",
    "# f\"gat_conv_[{gat_string}]_\" + \\\n",
    "# f\"use_dropout_{use_dropout}_\" + \\\n",
    "# f\"dropout_{dropout}_\" + \\\n",
    "# f\"predict_mode_stats_{predict_mode_stats}\" + \"/\"\n",
    "\n",
    "unique_model_description = \"single_districts_1pct/\"\n",
    "        \n",
    "run_path = run_path + unique_model_description\n",
    "base_case_path = '../../data/test_data/pop_1pm_basecase_mean_links_NEW.geojson'\n",
    "links_base_case = gpd.read_file(base_case_path, crs=\"EPSG:4326\")\n",
    "model_path = run_path +  'trained_model/model.pth'\n",
    "data_created_during_training = run_path + 'data_created_during_training/'\n",
    "scaler_x = joblib.load(data_created_during_training + 'test_x_scaler.pkl')\n",
    "scaler_pos = joblib.load(data_created_during_training + 'test_pos_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset created during training\n",
    "test_set_dl = torch.load(data_created_during_training + 'test_dl.pt')\n",
    "\n",
    "# Load the DataLoader parameters\n",
    "with open(data_created_during_training + 'test_loader_params.json', 'r') as f:\n",
    "    test_set_dl_loader_params = json.load(f)\n",
    "    \n",
    "# Remove or correct collate_fn if it is incorrectly specified\n",
    "if 'collate_fn' in test_set_dl_loader_params and isinstance(test_set_dl_loader_params['collate_fn'], str):\n",
    "    del test_set_dl_loader_params['collate_fn']  # Remove it to use the default collate function\n",
    "    \n",
    "test_set_loader = torch.utils.data.DataLoader(test_set_dl, **test_set_dl_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/chenhao-gnn/lib/python3.10/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized\n",
      "MyGnn(\n",
      "  (point_net_conv_1): PointNetConv(local_nn=Sequential(\n",
      "    (0): Linear(in_features=7, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  ), global_nn=Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "  ))\n",
      "  (point_net_conv_2): PointNetConv(local_nn=Sequential(\n",
      "    (0): Linear(in_features=514, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  ), global_nn=Sequential(\n",
      "    (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "  ))\n",
      "  (read_out_node_predictions): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (gat_graph_layers): Sequential(\n",
      "    (0) - TransformerConv(128, 64, heads=4): x, edge_index -> x\n",
      "    (1) - ReLU(inplace=True): x -> x\n",
      "    (2) - TransformerConv(256, 128, heads=4): x, edge_index -> x\n",
      "    (3) - ReLU(inplace=True): x -> x\n",
      "    (4) - TransformerConv(512, 64, heads=4): x, edge_index -> x\n",
      "    (5) - ReLU(inplace=True): x -> x\n",
      "    (6) - GATConv(256, 64, heads=1): x, edge_index -> x\n",
      "  )\n",
      "  (mode_stat_predictor): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      "  (additional_predictor): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=2048, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "point_net_conv_layer_structure_local_mlp = [int(x) for x in point_net_conv_layer_structure_local_mlp.split(',')]\n",
    "point_net_conv_layer_structure_global_mlp = [int(x) for x in point_net_conv_layer_structure_global_mlp.split(',')]\n",
    "gat_conv_layer_structure = [int(x) for x in gat_conv_layer_structure.split(',')]\n",
    "\n",
    "model = MyGnn(in_channels=in_channels, out_channels=out_channels, \n",
    "                    point_net_conv_layer_structure_local_mlp=point_net_conv_layer_structure_local_mlp, \n",
    "                    point_net_conv_layer_structure_global_mlp = point_net_conv_layer_structure_global_mlp,\n",
    "                    gat_conv_layer_structure=gat_conv_layer_structure,\n",
    "                    dropout=dropout,\n",
    "                    use_dropout=use_dropout, \n",
    "                    predict_mode_stats=predict_mode_stats)\n",
    "\n",
    "# Load the model state dictionary\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 260.02290836035036\n",
      "R-squared: 0.048076331615448\n",
      "Baseline Loss: 273.1551818847656\n"
     ]
    }
   ],
   "source": [
    "test_loss_my_test_data, r_squared_my_test_data, actual_vals_my_test_data, predictions_my_test_data, baseline_loss_my_test_data = hf.validate_model_on_test_set(model, test_set_loader.dataset, loss_fct, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss_my_test_data}\")\n",
    "print(f\"R-squared: {r_squared_my_test_data}\")\n",
    "print(f\"Baseline Loss: {baseline_loss_my_test_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next, we will look at single elements of the test set and visualize the performance of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0\n",
      "Test Loss: 2.0392765317644392\n",
      "R-squared: 0.01927924156188965\n",
      "Baseline Loss: 14.55555534362793\n",
      "Length of original_gdf: 31140\n",
      "Length of inversed_x: 31635\n"
     ]
    }
   ],
   "source": [
    "fixed_norm_max = 8\n",
    "\n",
    "i = 0\n",
    "\n",
    "my_test_data = test_set_loader.dataset[i]\n",
    "my_test_x = test_set_loader.dataset[i].x\n",
    "my_test_x = my_test_x.to('cpu')\n",
    "\n",
    "test_loss_my_test_data, r_squared_my_test_data, actual_vals_my_test_data, predictions_my_test_data, baseline_loss_my_test_data = hf.validate_model_on_test_set(model, my_test_data, loss_fct, device)\n",
    "print(f\"Test {i}\")\n",
    "print(f\"Test Loss: {test_loss_my_test_data}\")\n",
    "print(f\"R-squared: {r_squared_my_test_data}\")\n",
    "print(f\"Baseline Loss: {baseline_loss_my_test_data}\")\n",
    "\n",
    "inversed_x = scaler_x.inverse_transform(my_test_x)\n",
    "\n",
    "print(f\"Length of original_gdf: {len(links_base_case)}\")\n",
    "print(f\"Length of inversed_x: {inversed_x.shape[0]}\")  # Assuming inversed_x is a numpy array\n",
    "\n",
    "# AKTUELL STIMMEN DIE GROESSEN DER BEIDEN GDFS NICHT UEBEREIN. DIES FIXEN WENN READY. \n",
    "\n",
    "gdf_with_og_values = hf.data_to_geodataframe_with_og_values(data=my_test_data, original_gdf=links_base_case, predicted_values=predictions_my_test_data, inversed_x=inversed_x, use_all_features=False)\n",
    "gdf_with_og_values['capacity_reduction_rounded'] = gdf_with_og_values['capacity_reduction'].round(decimals=3)\n",
    "gdf_with_og_values['highway'] = gdf_with_og_values['highway'].map(hf.highway_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31635"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_test_x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIES KANN EIG AUCH RAUS\n",
    "\n",
    "hf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"vol_car_change_predicted\", \n",
    "                        save_it=True, number_to_plot=i, zone_to_plot = \"this zone\", is_predicted=True, alpha=0, use_fixed_norm=True, \n",
    "                        fixed_norm_max = fixed_norm_max,\n",
    "                        known_districts = False, buffer = 0.0005, districts_of_interest=None)\n",
    "hf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"vol_car_change_actual\", save_it=True, \n",
    "                        number_to_plot=i, zone_to_plot = \"this zone\",is_predicted=False,alpha=10,use_fixed_norm=True, \n",
    "                        fixed_norm_max = fixed_norm_max,\n",
    "                        known_districts = False, buffer = 0.0005, districts_of_interest=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0021],\n",
       "        [ 0.0021],\n",
       "        [ 0.0031],\n",
       "        ...,\n",
       "        [-0.0001],\n",
       "        [ 0.0004],\n",
       "        [ 0.0006]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO MC DROPOUT AFTERWARDS\n",
    "mean_predictions, uncertainties = mc_dropout_predict(model, test_data, num_samples=50, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chenhao-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
