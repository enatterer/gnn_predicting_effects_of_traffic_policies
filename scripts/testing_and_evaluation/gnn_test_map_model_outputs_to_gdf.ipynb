{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import wandb\n",
    "import pickle\n",
    "import os\n",
    "import shapely.wkt as wkt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "from torch_geometric.transforms import LineGraph\n",
    "\n",
    "import gzip\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import processing_io as pio\n",
    "\n",
    "# from gnn_architectures import MyGnn\n",
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the 'scripts' directory to the Python path\n",
    "scripts_path = os.path.abspath(os.path.join('..'))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "# Now you can import the gnn_io module\n",
    "import gnn_io as gio\n",
    "\n",
    "# import gnn_io as gio\n",
    "# import gnn_architectures as garch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = \"../../data/test_data/pop_1pm_policy_in_zone_1.geojson\"\n",
    "base_case = \"../../data/test_data/gdf_basecase_mean_pop_1pm.geojson\"\n",
    "test_data = gpd.read_file(test_data)\n",
    "base_case = gpd.read_file(base_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_object = pio.create_test_data_object(base_case= base_case, test_data = test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_list = [test_data_object]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_only_relevant_dimensions = gio.cut_dimensions(dataset=test_data_list, indices_of_dimensions_to_keep=[0, 1])\n",
    "dataset_normalized = gio.normalize_dataset(dataset_only_relevant_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 59135], pos=[31216, 2], num_nodes=31140, x=[31216, 2], y=[31216, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to the dataset\n",
    "dataset_normalized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset length: 1\n"
     ]
    }
   ],
   "source": [
    "test_dl = gio.create_dataloader(dataset=dataset_normalized, is_train=True, batch_size=16, train_ratio=0, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menatterer\u001b[0m (\u001b[33mtum-traffic-engineering\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/GNNs/GNN_predicting_effects_of_traffic_policies/scripts/testing_and_evaluation/wandb/run-20240712_113711-qeagpw6c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/test_with_1pct_data/runs/qeagpw6c' target=\"_blank\">gallant-sun-5</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/test_with_1pct_data' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/test_with_1pct_data' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/test_with_1pct_data</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/test_with_1pct_data/runs/qeagpw6c' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/test_with_1pct_data/runs/qeagpw6c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gnn_architectures'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m wandb\u001b[39m.\u001b[39minit(project\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest_with_1pct_data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m../../data/trained_models/model_with_feature_base_flow.pth\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/torch/serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1024\u001b[0m                 \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile,\n\u001b[1;32m   1026\u001b[0m                      map_location,\n\u001b[1;32m   1027\u001b[0m                      pickle_module,\n\u001b[1;32m   1028\u001b[0m                      overall_storage\u001b[39m=\u001b[39;49moverall_storage,\n\u001b[1;32m   1029\u001b[0m                      \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m   1030\u001b[0m \u001b[39mif\u001b[39;00m mmap:\n\u001b[1;32m   1031\u001b[0m     f_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(f, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/torch/serialization.py:1446\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1444\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1445\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> 1446\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   1448\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1449\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1450\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtorch.load.metadata\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mserialization_id\u001b[39m\u001b[39m\"\u001b[39m: zip_file\u001b[39m.\u001b[39mserialization_id()}\n\u001b[1;32m   1451\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.10/site-packages/torch/serialization.py:1439\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1438\u001b[0m mod_name \u001b[39m=\u001b[39m load_module_mapping\u001b[39m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m-> 1439\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfind_class(mod_name, name)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gnn_architectures'"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "wandb.init(project=\"test_with_1pct_data\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = torch.load('../../data/trained_models/model_with_feature_base_flow.pth')\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31216, 1])\n",
      "torch.Size([31216, 1])\n",
      "0.0020746015943586826\n",
      "Test Loss: 0.0020746015943586826\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the model\n",
    "def evaluate(model, test_dl, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for data in test_dl:\n",
    "            input_node_features, targets = data.x.to(device), data.y.to(device)\n",
    "            print(targets.shape)\n",
    "            outputs = model(data)\n",
    "            print(outputs.shape)\n",
    "            loss = torch.nn.MSELoss()(outputs, targets)\n",
    "            print(loss.item())\n",
    "            test_loss += loss.item()\n",
    "    avg_test_loss = test_loss / len(test_dl)\n",
    "    \n",
    "    # Log the test loss to Wandb\n",
    "    wandb.log({\"test_loss\": avg_test_loss})\n",
    "    return avg_test_loss, outputs\n",
    "\n",
    "# Evaluate the loaded model\n",
    "test_loss, outputs = evaluate(model, test_dl, device)\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31216, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "\n",
    "# def recreate_original_y_values(dataset):\n",
    "#     # Load the saved scaler\n",
    "#     scaler = joblib.load('y_scaler.pkl')\n",
    "\n",
    "#     # Apply the inverse transform to each data instance\n",
    "#     for data in dataset:\n",
    "#         data.y = torch.tensor(scaler.inverse_transform(data.y.numpy()), dtype=torch.float)\n",
    "\n",
    "#     return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 59135], pos=[31216, 2], num_nodes=31140, x=[31216, 2], y=[31216, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31216,)\n",
      "(31216,)\n",
      "(59135,)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'highway_mapping' and 'encode_modes' are defined as in your context\n",
    "highway_mapping = {\n",
    "    'residential': 0, 'tertiary': 1, 'living_street': 2, 'secondary': 3, \n",
    "    'primary': 4, 'trunk_link': 5, 'primary_link': 6, 'motorway': 7, \n",
    "    'service': 8, 'unclassified': 9, 'secondary_link': 10, \n",
    "    'pedestrian': 11, 'trunk': 12, 'motorway_link': 13, \n",
    "    'construction': 14, 'tertiary_link': 15, np.nan: -1\n",
    "}\n",
    "\n",
    "def data_to_geodataframe(data, original_gdf):\n",
    "    # Extract the edge index and node features\n",
    "    node_features = data.x.numpy()\n",
    "    target_values = data.y.numpy()\n",
    "\n",
    "    # Create edge data\n",
    "    edge_data = {\n",
    "        'from_node': original_gdf[\"from_node\"].values,\n",
    "        'to_node': original_gdf[\"to_node\"].values,\n",
    "        'capacity': node_features[:, 0],  # Assuming capacity is the first feature\n",
    "        'vol_base_case': node_features[:, 1],  # Assuming vol_base_case is the second feature\n",
    "        'vol_car': target_values.squeeze()  # Assuming target values are car volumes\n",
    "    }\n",
    "    # Convert to DataFrame\n",
    "    edge_df = pd.DataFrame(edge_data)\n",
    "    \n",
    "    # Create LineString geometry\n",
    "    edge_df['geometry'] = original_gdf[\"geometry\"].values\n",
    "\n",
    "    # Create GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(edge_df, geometry='geometry')\n",
    "\n",
    "    return gdf\n",
    "\n",
    "# Example usage\n",
    "# Assuming 'data' is your Data object and 'original_gdf' is the original GeoDataFrame\n",
    "predicted_gdf = data_to_geodataframe(test_data_object, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "      <th>capacity</th>\n",
       "      <th>vol_base_case</th>\n",
       "      <th>vol_car</th>\n",
       "      <th>from_coords</th>\n",
       "      <th>to_coords</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24972409</td>\n",
       "      <td>24972408</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.038307</td>\n",
       "      <td>0.037257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33869 48.85181, 2.33847 48.85181)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5904976363</td>\n",
       "      <td>24983651</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.049539</td>\n",
       "      <td>0.042657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33874 48.85242, 2.33872 48.85229)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24983651</td>\n",
       "      <td>5904976363</td>\n",
       "      <td>0.018110</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>0.006479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33872 48.85229, 2.33874 48.85242)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>664205947</td>\n",
       "      <td>24972376</td>\n",
       "      <td>0.018110</td>\n",
       "      <td>0.038909</td>\n",
       "      <td>0.032937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33994 48.85200, 2.33986 48.85181)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24972376</td>\n",
       "      <td>24972375</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.043923</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33986 48.85181, 2.33909 48.85152)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>324579210</td>\n",
       "      <td>4964831516</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.029483</td>\n",
       "      <td>0.024298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.34264 48.85031, 2.34258 48.85031)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4964831516</td>\n",
       "      <td>24972333</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.029483</td>\n",
       "      <td>0.024298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.34258 48.85031, 2.33999 48.84994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24972382</td>\n",
       "      <td>4964831514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.34151 48.85112, 2.34273 48.85065)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24972408</td>\n",
       "      <td>24972143</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.092659</td>\n",
       "      <td>0.085313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33847 48.85181, 2.33840 48.85172)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24972144</td>\n",
       "      <td>24972325</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>0.034017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LINESTRING (2.33806 48.85065, 2.33842 48.84991)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    from_node     to_node  capacity  vol_base_case   vol_car from_coords  \\\n",
       "0    24972409    24972408  0.006037       0.038307  0.037257         NaN   \n",
       "1  5904976363    24983651  0.006037       0.049539  0.042657         NaN   \n",
       "2    24983651  5904976363  0.018110       0.010830  0.006479         NaN   \n",
       "3   664205947    24972376  0.018110       0.038909  0.032937         NaN   \n",
       "4    24972376    24972375  0.006037       0.043923  0.038337         NaN   \n",
       "5   324579210  4964831516  0.006037       0.029483  0.024298         NaN   \n",
       "6  4964831516    24972333  0.006037       0.029483  0.024298         NaN   \n",
       "7    24972382  4964831514  0.000000       0.000000  0.000000         NaN   \n",
       "8    24972408    24972143  0.006037       0.092659  0.085313         NaN   \n",
       "9    24972144    24972325  0.006037       0.036302  0.034017         NaN   \n",
       "\n",
       "  to_coords                                         geometry  \n",
       "0       NaN  LINESTRING (2.33869 48.85181, 2.33847 48.85181)  \n",
       "1       NaN  LINESTRING (2.33874 48.85242, 2.33872 48.85229)  \n",
       "2       NaN  LINESTRING (2.33872 48.85229, 2.33874 48.85242)  \n",
       "3       NaN  LINESTRING (2.33994 48.85200, 2.33986 48.85181)  \n",
       "4       NaN  LINESTRING (2.33986 48.85181, 2.33909 48.85152)  \n",
       "5       NaN  LINESTRING (2.34264 48.85031, 2.34258 48.85031)  \n",
       "6       NaN  LINESTRING (2.34258 48.85031, 2.33999 48.84994)  \n",
       "7       NaN  LINESTRING (2.34151 48.85112, 2.34273 48.85065)  \n",
       "8       NaN  LINESTRING (2.33847 48.85181, 2.33840 48.85172)  \n",
       "9       NaN  LINESTRING (2.33806 48.85065, 2.33842 48.84991)  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_gdf.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
