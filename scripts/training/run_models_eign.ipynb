{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used for debugging. Should have the same functionality as run_models.py, but with more verbose output.\n",
    "\n",
    "**[TODO]** Update from run_models.py when the dust settles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "# Add the 'scripts' directory to Python Path\n",
    "scripts_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "from training.help_functions import *\n",
    "\n",
    "from gnn.help_functions import (\n",
    "    GNN_Loss,\n",
    "    compute_baseline_of_mean_target,\n",
    "    compute_baseline_of_no_policies,\n",
    ")\n",
    "from gnn.models.point_net_transf_gat import PointNetTransfGAT\n",
    "from gnn.models.eign import EIGNLaplacianConv\n",
    "\n",
    "\n",
    "model = EIGNLaplacianConv(\n",
    "    in_channels_signed= 5,\n",
    "    out_channels_signed= 1,\n",
    "    in_channels_unsigned= 5,\n",
    "    out_channels_unsigned= 1,\n",
    "    hidden_channels_signed=32,\n",
    "    hidden_channels_unsigned=32,\n",
    "    num_blocks=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "\n",
    "# Please adjust as needed\n",
    "dataset_path = os.path.join(project_root, \"data2\", \"train_data\", \"edge_features\")\n",
    "base_dir = os.path.join(project_root, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS = [\n",
    "    \"project_name\",\n",
    "    \"predict_mode_stats\",\n",
    "    \"in_channels\",\n",
    "    \"use_all_features\",\n",
    "    \"out_channels\",\n",
    "    \"loss_fct\",\n",
    "    \"use_weighted_loss\",\n",
    "    \"point_net_conv_layer_structure_local_mlp\",\n",
    "    \"point_net_conv_layer_structure_global_mlp\",\n",
    "    \"gat_conv_layer_structure\",\n",
    "    \"use_bootstrapping\",\n",
    "    \"num_epochs\",\n",
    "    \"batch_size\",\n",
    "    \"lr\",\n",
    "    \"early_stopping_patience\",\n",
    "    \"use_dropout\",\n",
    "    \"dropout\",\n",
    "    \"gradient_accumulation_steps\",\n",
    "    \"use_gradient_clipping\",\n",
    "    \"device_nr\",\n",
    "    \"unique_model_description\",\n",
    "    \"use_monte_carlo_dropout\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_parameters(args):\n",
    "\n",
    "    params = {\n",
    "        # KEEP IN MIND: IF WE CHANGE PARAMETERS, WE NEED TO CHANGE THE NAME OF THE RUN IN WANDB (for the config)\n",
    "        \"project_name\": \"eign\",\n",
    "        \"predict_mode_stats\": args.predict_mode_stats,\n",
    "        \"in_channels\": args.in_channels,\n",
    "        \"use_all_features\": args.use_all_features,\n",
    "        \"out_channels\": args.out_channels,\n",
    "        \"loss_fct\": args.loss_fct,\n",
    "        \"use_weighted_loss\": args.use_weighted_loss,\n",
    "        \"point_net_conv_layer_structure_local_mlp\": [\n",
    "            int(x) for x in args.point_net_conv_layer_structure_local_mlp.split(\",\")\n",
    "        ],\n",
    "        \"point_net_conv_layer_structure_global_mlp\": [\n",
    "            int(x) for x in args.point_net_conv_layer_structure_global_mlp.split(\",\")\n",
    "        ],\n",
    "        \"gat_conv_layer_structure\": [\n",
    "            int(x) for x in args.gat_conv_layer_structure.split(\",\")\n",
    "        ],\n",
    "        \"use_bootstrapping\": args.use_bootstrapping,\n",
    "        \"num_epochs\": args.num_epochs,\n",
    "        \"batch_size\": int(args.batch_size),\n",
    "        \"lr\": float(args.lr),\n",
    "        \"early_stopping_patience\": args.early_stopping_patience,\n",
    "        \"use_dropout\": args.use_dropout,\n",
    "        \"dropout\": args.dropout,\n",
    "        \"gradient_accumulation_steps\": args.gradient_accumulation_steps,\n",
    "        \"use_gradient_clipping\": args.use_gradient_clipping,\n",
    "        \"device_nr\": args.device_nr,\n",
    "        \"use_monte_carlo_dropout\": args.use_monte_carlo_dropout,\n",
    "    }\n",
    "\n",
    "    params[\"unique_model_description\"] = \"eign_implementing\"\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch number: 1\n",
      "Processing batch number: 2\n",
      "Processing batch number: 3\n",
      "Processing batch number: 4\n",
      "Processing batch number: 5\n",
      "Processing batch number: 6\n",
      "Processing batch number: 7\n",
      "Processing batch number: 8\n",
      "Processing batch number: 9\n",
      "Loaded 450 items into datalist\n"
     ]
    }
   ],
   "source": [
    "datalist = []\n",
    "batch_num = 1\n",
    "while True and batch_num < 10:  # Change this to \"and batch_num < 10\" for a faster run\n",
    "    print(f\"Processing batch number: {batch_num}\")\n",
    "    # total_memory, available_memory, used_memory = get_memory_info()\n",
    "    # print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "    # print(f\"Available Memory: {available_memory:.2f} GB\")\n",
    "    # print(f\"Used Memory: {used_memory:.2f} GB\")\n",
    "    batch_file = os.path.join(dataset_path, f\"datalist_batch_{batch_num}.pt\")\n",
    "    if not os.path.exists(batch_file):\n",
    "        break\n",
    "    batch_data = torch.load(batch_file, map_location=\"cpu\")\n",
    "    if isinstance(batch_data, list):\n",
    "        datalist.extend(batch_data)\n",
    "    batch_num += 1\n",
    "print(f\"Loaded {len(datalist)} items into datalist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the argparse section with this:\n",
    "args = {\n",
    "    \"in_channels\": 5,\n",
    "    \"use_all_features\": False,\n",
    "    \"out_channels\": 1,\n",
    "    \"loss_fct\": \"mse\",\n",
    "    \"use_weighted_loss\": True,\n",
    "    \"predict_mode_stats\": False,\n",
    "    \"point_net_conv_layer_structure_local_mlp\": \"256\",\n",
    "    \"point_net_conv_layer_structure_global_mlp\": \"512\",\n",
    "    \"gat_conv_layer_structure\": \"128,256,512,256\",\n",
    "    \"use_bootstrapping\": False,\n",
    "    \"num_epochs\": 20,\n",
    "    \"batch_size\": 1,\n",
    "    \"lr\": 0.001,\n",
    "    \"early_stopping_patience\": 5,\n",
    "    \"use_dropout\": True,\n",
    "    \"dropout\": 0.3,\n",
    "    \"gradient_accumulation_steps\": 3,\n",
    "    \"use_gradient_clipping\": True,\n",
    "    \"lr_scheduler_warmup_steps\": 10000,\n",
    "    \"device_nr\": 0,\n",
    "    \"use_monte_carlo_dropout\": True,\n",
    "}\n",
    "\n",
    "\n",
    "# Convert the dictionary to an object with attributes\n",
    "class Args:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "\n",
    "args = Args(**args)\n",
    "set_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0 with CUDA_VISIBLE_DEVICES=0\n",
      "Starting prepare_data_with_graph_features with 450 items\n",
      "Splitting into subsets...\n",
      "Total dataset length: 450\n",
      "Training subset length: 360\n",
      "Validation subset length: 67\n",
      "Test subset length: 23\n",
      "Split complete. Train: 360, Valid: 67, Test: 23\n",
      "Saving test set...\n",
      "Test set saved to /home/duc-nguyen/Downloads/projects/gnn_predicting_effects_of_traffic_policies/data/eign/eign_implementing/data_created_during_training/test_set.pt\n",
      "Normalizing train set...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 4/4 [00:00<00:00,  4.99it/s]\n",
      "Normalizing x features: 100%|██████████| 4/4 [00:00<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n",
      "Fitting and normalizing pos features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "Normalizing pos features: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos features normalized\n",
      "Train set normalized\n",
      "Normalizing validation set...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00,  6.05it/s]\n",
      "Normalizing x features: 100%|██████████| 1/1 [00:00<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n",
      "Fitting and normalizing pos features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s]\n",
      "Normalizing pos features: 100%|██████████| 1/1 [00:00<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos features normalized\n",
      "Validation set normalized\n",
      "Normalizing test set...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00, 18.78it/s]\n",
      "Normalizing x features: 100%|██████████| 1/1 [00:00<00:00, 37.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n",
      "Fitting and normalizing pos features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00, 19.10it/s]\n",
      "Normalizing pos features: 100%|██████████| 1/1 [00:00<00:00, 35.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos features normalized\n",
      "Test set normalized\n",
      "Creating train loader...\n",
      "Train loader created\n",
      "Creating validation loader...\n",
      "Validation loader created\n",
      "Creating test loader...\n",
      "Test loader created\n",
      "Dataloaders and scalers saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthuaduc24042001\u001b[0m (\u001b[33mthuaduc24042001-technical-university-of-munich\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/duc-nguyen/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/training/wandb/run-20250515_012653-mcmk63qb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign/runs/mcmk63qb' target=\"_blank\">eign_implementing</a></strong> to <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign' target=\"_blank\">https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign/runs/mcmk63qb' target=\"_blank\">https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign/runs/mcmk63qb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpus = get_available_gpus()\n",
    "best_gpu = select_best_gpu(gpus)\n",
    "set_cuda_visible_device(best_gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "params = get_parameters(args)\n",
    "\n",
    "# Create directory for the run\n",
    "unique_run_dir = os.path.join(\n",
    "    base_dir, params[\"project_name\"], params[\"unique_model_description\"]\n",
    ")\n",
    "os.makedirs(unique_run_dir, exist_ok=True)\n",
    "\n",
    "model_save_path, path_to_save_dataloader = get_paths(\n",
    "    base_dir=os.path.join(base_dir, params[\"project_name\"]),\n",
    "    unique_model_description=params[\"unique_model_description\"],\n",
    "    model_save_path=\"trained_model/model.pth\",\n",
    ")\n",
    "\n",
    "train_dl, valid_dl, scalers_train, scalers_validation = (\n",
    "    prepare_data_with_graph_features(\n",
    "        datalist=datalist,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        path_to_save_dataloader=path_to_save_dataloader,\n",
    "        use_all_features=params[\"use_all_features\"],\n",
    "        use_bootstrapping=params[\"use_bootstrapping\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "config = setup_wandb({param: params[param] for param in PARAMETERS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(architecture: str, config: object, device: torch.device):\n",
    "    \"\"\"\n",
    "    Factory function to create the specified model architecture.\n",
    "\n",
    "    Parameters:\n",
    "    - architecture: str, the name of the architecture to use\n",
    "    - config: object containing model parameters\n",
    "    - device: torch device to put the model on\n",
    "\n",
    "    Returns:\n",
    "    - Initialized model on the specified device\n",
    "    \"\"\"\n",
    "    if architecture == \"point_net_transf_gat\":\n",
    "        return PointNetTransfGAT(\n",
    "            in_channels=config.in_channels,\n",
    "            out_channels=config.out_channels,\n",
    "            point_net_conv_layer_structure_local_mlp=config.point_net_conv_layer_structure_local_mlp,\n",
    "            point_net_conv_layer_structure_global_mlp=config.point_net_conv_layer_structure_global_mlp,\n",
    "            gat_conv_layer_structure=config.gat_conv_layer_structure,\n",
    "            use_dropout=config.use_dropout,\n",
    "            dropout=config.dropout,\n",
    "            predict_mode_stats=config.predict_mode_stats,\n",
    "            dtype=torch.float32,\n",
    "        ).to(device)\n",
    "    elif architecture == \"eign\":\n",
    "        return EIGNLaplacianConv(\n",
    "            in_channels_signed=5,\n",
    "            out_channels_signed=1,\n",
    "            in_channels_unsigned=5,\n",
    "            out_channels_unsigned=1,\n",
    "            hidden_channels_signed=32,\n",
    "            hidden_channels_unsigned=32,\n",
    "            num_blocks=4,\n",
    "        ).to(device)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown architecture: {architecture}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline loss mean 27.29950714111328\n",
      "baseline loss no  27.20518684387207\n"
     ]
    }
   ],
   "source": [
    "# gnn_instance = create_model(\"point_net_transf_gat\", config, device)\n",
    "gnn_instance = create_model(\"eign\", config, device)\n",
    "\n",
    "\n",
    "model = gnn_instance.to(device)\n",
    "loss_fct = GNN_Loss(\n",
    "    config.loss_fct, datalist[0].x.shape[0], device, config.use_weighted_loss\n",
    ")\n",
    "\n",
    "baseline_loss_mean_target = compute_baseline_of_mean_target(\n",
    "    dataset=train_dl, loss_fct=loss_fct, device=device, scalers=scalers_train\n",
    ")\n",
    "baseline_loss = compute_baseline_of_no_policies(\n",
    "    dataset=train_dl, loss_fct=loss_fct, device=device, scalers=scalers_train\n",
    ")\n",
    "print(\"baseline loss mean \" + str(baseline_loss_mean_target))\n",
    "print(\"baseline loss no  \" + str(baseline_loss))\n",
    "\n",
    "early_stopping = EarlyStopping(patience=params[\"early_stopping_patience\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this method is being called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/360 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_val_loss, best_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mgnn_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscalers_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalers_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscalers_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalers_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_save_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with validation loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/gnn/models/eign.py:233\u001b[0m, in \u001b[0;36mEIGN.train_model\u001b[0;34m(self, config, loss_fct, optimizer, train_dl, valid_dl, device, early_stopping, model_save_path, scalers_train, scalers_validation)\u001b[0m\n\u001b[1;32m    231\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m train_loss_node_predictions \u001b[38;5;241m+\u001b[39m train_loss_mode_stats\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 233\u001b[0m         predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx_signed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx_unsigned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_directed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_is_directed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munsigned\n\u001b[1;32m    239\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m loss_fct(\n\u001b[1;32m    240\u001b[0m             predicted, targets_node_predictions, x_unscaled\n\u001b[1;32m    241\u001b[0m         )\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/gnn/models/eign.py:140\u001b[0m, in \u001b[0;36mEIGN.forward\u001b[0;34m(self, x_signed, x_unsigned, edge_index, is_directed, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     x_unsigned \u001b[38;5;241m=\u001b[39m x_unsigned\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)      \n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 140\u001b[0m     x_signed, x_unsigned \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_signed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_signed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_unsigned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_unsigned\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_directed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_directed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x_signed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m         x_signed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigned_activation_fn(x_signed)\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/gnn/models/block/block.py:200\u001b[0m, in \u001b[0;36mEIGNBlock.forward\u001b[0;34m(self, x_signed, x_unsigned, edge_index, is_directed)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# Convolutions\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_signed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m x_signed\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 200\u001b[0m     h_signed_signed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigned_conv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_signed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_directed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_directed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_signed_to_unsigned_conv:\n\u001b[1;32m    206\u001b[0m         h_signed_unsigned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigned_unsigned_conv(\n\u001b[1;32m    207\u001b[0m             edge_index\u001b[38;5;241m=\u001b[39medge_index,\n\u001b[1;32m    208\u001b[0m             x\u001b[38;5;241m=\u001b[39mx_signed,\n\u001b[1;32m    209\u001b[0m             is_directed\u001b[38;5;241m=\u001b[39mis_directed,\n\u001b[1;32m    210\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/gnn/models/conv/residual.py:22\u001b[0m, in \u001b[0;36mResidualWrapper.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
     ]
    }
   ],
   "source": [
    "best_val_loss, best_epoch = gnn_instance.train_model(\n",
    "    config=config,\n",
    "    loss_fct=loss_fct,\n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=1e-4),\n",
    "    train_dl=train_dl,\n",
    "    valid_dl=valid_dl,\n",
    "    device=device,\n",
    "    early_stopping=early_stopping,\n",
    "    model_save_path=model_save_path,\n",
    "    scalers_train=scalers_train,\n",
    "    scalers_validation=scalers_validation,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Best model saved to {model_save_path} with validation loss: {best_val_loss} at epoch {best_epoch}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
