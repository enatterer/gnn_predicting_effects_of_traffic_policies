{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used for debugging. Should have the same functionality as run_models.py, but with more verbose output.\n",
    "\n",
    "**[TODO]** Update from run_models.py when the dust settles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "# Add the 'scripts' directory to Python Path\n",
    "scripts_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "from training.help_functions import *\n",
    "\n",
    "from gnn.help_functions import EIGN_Loss, compute_baseline_of_mean_target, compute_baseline_of_no_policies\n",
    "from gnn.models.point_net_transf_gat import PointNetTransfGAT\n",
    "from gnn.models.eign import EIGNLaplacianConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "\n",
    "# Please adjust as needed\n",
    "dataset_path = os.path.join(\n",
    "    project_root, \"data\", \"train_data\", \"edge_features_with_net_flow_aggregated\"\n",
    ")\n",
    "base_dir = os.path.join(project_root, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS = [\n",
    "    \"project_name\",\n",
    "    \"predict_mode_stats\",\n",
    "    \"in_channels\",\n",
    "    \"use_all_features\",\n",
    "    \"out_channels\",\n",
    "    \"loss_fct\",\n",
    "    \"use_weighted_loss\",\n",
    "    \"point_net_conv_layer_structure_local_mlp\",\n",
    "    \"point_net_conv_layer_structure_global_mlp\",\n",
    "    \"gat_conv_layer_structure\",\n",
    "    \"use_bootstrapping\",\n",
    "    \"num_epochs\",\n",
    "    \"batch_size\",\n",
    "    \"lr\",\n",
    "    \"early_stopping_patience\",\n",
    "    \"use_dropout\",\n",
    "    \"dropout\",\n",
    "    \"gradient_accumulation_steps\",\n",
    "    \"use_gradient_clipping\",\n",
    "    \"device_nr\",\n",
    "    \"unique_model_description\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_parameters(args):\n",
    "\n",
    "    params = {\n",
    "        # KEEP IN MIND: IF WE CHANGE PARAMETERS, WE NEED TO CHANGE THE NAME OF THE RUN IN WANDB (for the config)\n",
    "        \"project_name\": \"IDP\",\n",
    "        \"predict_mode_stats\": args.predict_mode_stats,\n",
    "        \"in_channels\": args.in_channels,\n",
    "        \"use_all_features\": args.use_all_features,\n",
    "        \"out_channels\": args.out_channels,\n",
    "        \"loss_fct\": args.loss_fct,\n",
    "        \"use_weighted_loss\": args.use_weighted_loss,\n",
    "        \"point_net_conv_layer_structure_local_mlp\": [\n",
    "            int(x) for x in args.point_net_conv_layer_structure_local_mlp.split(\",\")\n",
    "        ],\n",
    "        \"point_net_conv_layer_structure_global_mlp\": [\n",
    "            int(x) for x in args.point_net_conv_layer_structure_global_mlp.split(\",\")\n",
    "        ],\n",
    "        \"gat_conv_layer_structure\": [\n",
    "            int(x) for x in args.gat_conv_layer_structure.split(\",\")\n",
    "        ],\n",
    "        \"use_bootstrapping\": args.use_bootstrapping,\n",
    "        \"num_epochs\": args.num_epochs,\n",
    "        \"batch_size\": int(args.batch_size),\n",
    "        \"lr\": float(args.lr),\n",
    "        \"early_stopping_patience\": args.early_stopping_patience,\n",
    "        \"use_dropout\": args.use_dropout,\n",
    "        \"dropout\": args.dropout,\n",
    "        \"gradient_accumulation_steps\": args.gradient_accumulation_steps,\n",
    "        \"use_gradient_clipping\": args.use_gradient_clipping,\n",
    "        \"device_nr\": args.device_nr,\n",
    "    }\n",
    "\n",
    "    params[\"unique_model_description\"] = \"eign\"\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch number: 1\n",
      "Processing batch number: 2\n",
      "Processing batch number: 3\n",
      "Processing batch number: 4\n",
      "Processing batch number: 5\n",
      "Processing batch number: 6\n",
      "Processing batch number: 7\n",
      "Processing batch number: 8\n",
      "Processing batch number: 9\n",
      "Processing batch number: 10\n",
      "Processing batch number: 11\n",
      "Processing batch number: 12\n",
      "Processing batch number: 13\n",
      "Processing batch number: 14\n",
      "Processing batch number: 15\n",
      "Processing batch number: 16\n",
      "Processing batch number: 9\n",
      "Processing batch number: 10\n",
      "Processing batch number: 11\n",
      "Processing batch number: 12\n",
      "Processing batch number: 13\n",
      "Processing batch number: 14\n",
      "Processing batch number: 15\n",
      "Processing batch number: 16\n",
      "Processing batch number: 17\n",
      "Processing batch number: 18\n",
      "Processing batch number: 19\n",
      "Processing batch number: 17\n",
      "Processing batch number: 18\n",
      "Processing batch number: 19\n",
      "Processing batch number: 20\n",
      "Processing batch number: 21\n",
      "Processing batch number: 22\n",
      "Processing batch number: 23\n",
      "Processing batch number: 24\n",
      "Processing batch number: 25\n",
      "Processing batch number: 26\n",
      "Processing batch number: 27\n",
      "Processing batch number: 20\n",
      "Processing batch number: 21\n",
      "Processing batch number: 22\n",
      "Processing batch number: 23\n",
      "Processing batch number: 24\n",
      "Processing batch number: 25\n",
      "Processing batch number: 26\n",
      "Processing batch number: 27\n",
      "Processing batch number: 28\n",
      "Processing batch number: 29\n",
      "Processing batch number: 30\n",
      "Processing batch number: 31\n",
      "Processing batch number: 32\n",
      "Processing batch number: 33\n",
      "Processing batch number: 34\n",
      "Processing batch number: 35\n",
      "Processing batch number: 28\n",
      "Processing batch number: 29\n",
      "Processing batch number: 30\n",
      "Processing batch number: 31\n",
      "Processing batch number: 32\n",
      "Processing batch number: 33\n",
      "Processing batch number: 34\n",
      "Processing batch number: 35\n",
      "Processing batch number: 36\n",
      "Processing batch number: 37\n",
      "Processing batch number: 38\n",
      "Processing batch number: 39\n",
      "Processing batch number: 40\n",
      "Processing batch number: 41\n",
      "Processing batch number: 42\n",
      "Processing batch number: 43\n",
      "Processing batch number: 36\n",
      "Processing batch number: 37\n",
      "Processing batch number: 38\n",
      "Processing batch number: 39\n",
      "Processing batch number: 40\n",
      "Processing batch number: 41\n",
      "Processing batch number: 42\n",
      "Processing batch number: 43\n",
      "Processing batch number: 44\n",
      "Processing batch number: 45\n",
      "Processing batch number: 46\n",
      "Processing batch number: 47\n",
      "Processing batch number: 48\n",
      "Processing batch number: 49\n",
      "Processing batch number: 50\n",
      "Processing batch number: 51\n",
      "Processing batch number: 44\n",
      "Processing batch number: 45\n",
      "Processing batch number: 46\n",
      "Processing batch number: 47\n",
      "Processing batch number: 48\n",
      "Processing batch number: 49\n",
      "Processing batch number: 50\n",
      "Processing batch number: 51\n",
      "Processing batch number: 52\n",
      "Processing batch number: 53\n",
      "Processing batch number: 54\n",
      "Processing batch number: 55\n",
      "Processing batch number: 56\n",
      "Processing batch number: 57\n",
      "Processing batch number: 58\n",
      "Processing batch number: 59\n",
      "Processing batch number: 52\n",
      "Processing batch number: 53\n",
      "Processing batch number: 54\n",
      "Processing batch number: 55\n",
      "Processing batch number: 56\n",
      "Processing batch number: 57\n",
      "Processing batch number: 58\n",
      "Processing batch number: 59\n",
      "Processing batch number: 60\n",
      "Processing batch number: 61\n",
      "Processing batch number: 62\n",
      "Processing batch number: 63\n",
      "Processing batch number: 64\n",
      "Processing batch number: 65\n",
      "Processing batch number: 66\n",
      "Processing batch number: 67\n",
      "Processing batch number: 60\n",
      "Processing batch number: 61\n",
      "Processing batch number: 62\n",
      "Processing batch number: 63\n",
      "Processing batch number: 64\n",
      "Processing batch number: 65\n",
      "Processing batch number: 66\n",
      "Processing batch number: 67\n",
      "Processing batch number: 68\n",
      "Processing batch number: 69\n",
      "Processing batch number: 70\n",
      "Processing batch number: 71\n",
      "Processing batch number: 72\n",
      "Processing batch number: 73\n",
      "Processing batch number: 74\n",
      "Processing batch number: 68\n",
      "Processing batch number: 69\n",
      "Processing batch number: 70\n",
      "Processing batch number: 71\n",
      "Processing batch number: 72\n",
      "Processing batch number: 73\n",
      "Processing batch number: 74\n",
      "Processing batch number: 75\n",
      "Processing batch number: 76\n",
      "Processing batch number: 77\n",
      "Processing batch number: 78\n",
      "Processing batch number: 79\n",
      "Processing batch number: 80\n",
      "Processing batch number: 81\n",
      "Processing batch number: 82\n",
      "Processing batch number: 75\n",
      "Processing batch number: 76\n",
      "Processing batch number: 77\n",
      "Processing batch number: 78\n",
      "Processing batch number: 79\n",
      "Processing batch number: 80\n",
      "Processing batch number: 81\n",
      "Processing batch number: 82\n",
      "Processing batch number: 83\n",
      "Processing batch number: 84\n",
      "Processing batch number: 85\n",
      "Processing batch number: 86\n",
      "Processing batch number: 87\n",
      "Processing batch number: 88\n",
      "Processing batch number: 89\n",
      "Processing batch number: 90\n",
      "Processing batch number: 83\n",
      "Processing batch number: 84\n",
      "Processing batch number: 85\n",
      "Processing batch number: 86\n",
      "Processing batch number: 87\n",
      "Processing batch number: 88\n",
      "Processing batch number: 89\n",
      "Processing batch number: 90\n",
      "Processing batch number: 91\n",
      "Processing batch number: 92\n",
      "Processing batch number: 93\n",
      "Processing batch number: 94\n",
      "Processing batch number: 95\n",
      "Processing batch number: 96\n",
      "Processing batch number: 97\n",
      "Processing batch number: 91\n",
      "Processing batch number: 92\n",
      "Processing batch number: 93\n",
      "Processing batch number: 94\n",
      "Processing batch number: 95\n",
      "Processing batch number: 96\n",
      "Processing batch number: 97\n",
      "Processing batch number: 98\n",
      "Processing batch number: 99\n",
      "Processing batch number: 100\n",
      "Processing batch number: 101\n",
      "Loaded 4984 items into datalist\n",
      "Processing batch number: 98\n",
      "Processing batch number: 99\n",
      "Processing batch number: 100\n",
      "Processing batch number: 101\n",
      "Loaded 4984 items into datalist\n"
     ]
    }
   ],
   "source": [
    "datalist = []\n",
    "batch_num = 1\n",
    "while True:  # Change this to \"and batch_num < 10\" for a faster run\n",
    "    print(f\"Processing batch number: {batch_num}\")\n",
    "    # total_memory, available_memory, used_memory = get_memory_info()\n",
    "    # print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "    # print(f\"Available Memory: {available_memory:.2f} GB\")\n",
    "    # print(f\"Used Memory: {used_memory:.2f} GB\")\n",
    "    batch_file = os.path.join(dataset_path, f\"datalist_batch_{batch_num}.pt\")\n",
    "    if not os.path.exists(batch_file):\n",
    "        break\n",
    "    batch_data = torch.load(batch_file, map_location=\"cpu\")\n",
    "    if isinstance(batch_data, list):\n",
    "        datalist.extend(batch_data)\n",
    "    batch_num += 1\n",
    "print(f\"Loaded {len(datalist)} items into datalist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the argparse section with this:\n",
    "args = {\n",
    "    \"in_channels\": 5,\n",
    "    \"use_all_features\": False,\n",
    "    \"out_channels\": 1,\n",
    "    \"loss_fct\": \"mse\",\n",
    "    \"use_weighted_loss\": True,\n",
    "    \"predict_mode_stats\": False,\n",
    "    \"point_net_conv_layer_structure_local_mlp\": \"256\",\n",
    "    \"point_net_conv_layer_structure_global_mlp\": \"512\",\n",
    "    \"gat_conv_layer_structure\": \"128,256,512,256\",\n",
    "    \"use_bootstrapping\": False,\n",
    "    \"num_epochs\": 100,\n",
    "    \"batch_size\": 8,\n",
    "    \"lr\": 0.001,\n",
    "    \"early_stopping_patience\": 20,\n",
    "    \"use_dropout\": True,\n",
    "    \"dropout\": 0.3,\n",
    "    \"gradient_accumulation_steps\": 3,\n",
    "    \"use_gradient_clipping\": True,\n",
    "    \"lr_scheduler_warmup_steps\": 10000,\n",
    "    \"device_nr\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "# Convert the dictionary to an object with attributes\n",
    "class Args:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "\n",
    "args = Args(**args)\n",
    "set_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0 with CUDA_VISIBLE_DEVICES=0\n",
      "Starting prepare_data_with_graph_features with 4984 items\n",
      "Splitting into subsets...\n",
      "Total dataset length: 4984\n",
      "Training subset length: 3987\n",
      "Validation subset length: 747\n",
      "Test subset length: 250\n",
      "Split complete. Train: 3987, Valid: 747, Test: 250\n",
      "Normalizing train set...\n",
      "Fitting and normalizing x features...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 40/40 [00:08<00:00,  4.80it/s]\n",
      "Fitting scaler: 100%|██████████| 40/40 [00:08<00:00,  4.80it/s]\n",
      "Normalizing x features: 100%|██████████| 40/40 [00:05<00:00,  7.14it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting x_signed scaler: 100%|██████████| 4/4 [00:00<00:00,  6.63it/s]\n",
      "Fitting x_signed scaler: 100%|██████████| 4/4 [00:00<00:00,  6.63it/s]\n",
      "Normalizing x_signed features: 100%|██████████| 4/4 [00:00<00:00,  4.06it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting and normalizing pos features...\n",
      "Train set normalized\n",
      "Normalizing validation set...\n",
      "Fitting and normalizing x features...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 8/8 [00:01<00:00,  4.72it/s]\n",
      "Fitting scaler: 100%|██████████| 8/8 [00:01<00:00,  4.72it/s]\n",
      "Normalizing x features: 100%|██████████| 8/8 [00:01<00:00,  7.30it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting x_signed scaler: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n",
      "Fitting x_signed scaler: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n",
      "Normalizing x_signed features: 100%|██████████| 1/1 [00:00<00:00,  5.76it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting and normalizing pos features...\n",
      "Validation set normalized\n",
      "Normalizing test set...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 3/3 [00:00<00:00,  5.58it/s]\n",
      "Fitting scaler: 100%|██████████| 3/3 [00:00<00:00,  5.58it/s]\n",
      "Normalizing x features: 100%|██████████| 3/3 [00:00<00:00,  7.87it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting x_signed scaler: 100%|██████████| 1/1 [00:00<00:00, 28.45it/s]\n",
      "Fitting x_signed scaler: 100%|██████████| 1/1 [00:00<00:00, 28.45it/s]\n",
      "Normalizing x_signed features: 100%|██████████| 1/1 [00:00<00:00, 19.27it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting and normalizing pos features...\n",
      "Test set normalized\n",
      "Creating train loader...\n",
      "Train loader created\n",
      "Creating validation loader...\n",
      "Validation loader created\n",
      "Creating test loader...\n",
      "Test loader created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders and scalers saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthuaduc24042001\u001b[0m (\u001b[33mthuaduc24042001-technical-university-of-munich\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.20.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dnguyen/gnn_predicting_effects_of_traffic_policies/scripts/training/wandb/run-20250607_114841-fsywze96</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP/runs/fsywze96' target=\"_blank\">eign</a></strong> to <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP' target=\"_blank\">https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP/runs/fsywze96' target=\"_blank\">https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP/runs/fsywze96</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpus = get_available_gpus()\n",
    "best_gpu = select_best_gpu(gpus)\n",
    "set_cuda_visible_device(best_gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "params = get_parameters(args)\n",
    "\n",
    "# Create directory for the run\n",
    "unique_run_dir = os.path.join(\n",
    "    base_dir, params[\"project_name\"], params[\"unique_model_description\"]\n",
    ")\n",
    "os.makedirs(unique_run_dir, exist_ok=True)\n",
    "\n",
    "model_save_path, path_to_save_dataloader = get_paths(\n",
    "    base_dir=os.path.join(base_dir, params[\"project_name\"]),\n",
    "    unique_model_description=params[\"unique_model_description\"],\n",
    "    model_save_path=\"trained_model/model.pth\",\n",
    ")\n",
    "train_dl, valid_dl, scalers_train, scalers_validation = (\n",
    "    prepare_data_with_graph_features(\n",
    "        datalist=datalist,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        path_to_save_dataloader=path_to_save_dataloader,\n",
    "        use_all_features=params[\"use_all_features\"],\n",
    "        use_bootstrapping=params[\"use_bootstrapping\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "config = setup_wandb({param: params[param] for param in PARAMETERS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(architecture: str, config: object, device: torch.device):\n",
    "    \"\"\"\n",
    "    Factory function to create the specified model architecture.\n",
    "\n",
    "    Parameters:\n",
    "    - architecture: str, the name of the architecture to use\n",
    "    - config: object containing model parameters\n",
    "    - device: torch device to put the model on\n",
    "\n",
    "    Returns:\n",
    "    - Initialized model on the specified device\n",
    "    \"\"\"\n",
    "    if architecture == \"point_net_transf_gat\":\n",
    "        return PointNetTransfGAT(\n",
    "            in_channels=config.in_channels,\n",
    "            out_channels=config.out_channels,\n",
    "            point_net_conv_layer_structure_local_mlp=config.point_net_conv_layer_structure_local_mlp,\n",
    "            point_net_conv_layer_structure_global_mlp=config.point_net_conv_layer_structure_global_mlp,\n",
    "            gat_conv_layer_structure=config.gat_conv_layer_structure,\n",
    "            use_dropout=config.use_dropout,\n",
    "            dropout=config.dropout,\n",
    "            predict_mode_stats=config.predict_mode_stats,\n",
    "            dtype=torch.float32,\n",
    "        ).to(device)\n",
    "    elif architecture == \"eign\":\n",
    "        # TO BE IMPLEMENTED\n",
    "        return EIGNLaplacianConv(\n",
    "            in_channels_signed=1,\n",
    "            out_channels_signed=1,\n",
    "            in_channels_unsigned=5,\n",
    "            out_channels_unsigned=1,\n",
    "            hidden_channels_signed=32,\n",
    "            hidden_channels_unsigned=32,\n",
    "            num_blocks=4,\n",
    "        ).to(device)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown architecture: {architecture}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline loss mean 4.058615684509277\n",
      "baseline loss no  4.065121173858643\n"
     ]
    }
   ],
   "source": [
    "gnn_instance = create_model(\"eign\", config, device)\n",
    "\n",
    "\n",
    "\n",
    "model = gnn_instance.to(device)\n",
    "loss_fct = EIGN_Loss(\n",
    "    config.loss_fct, datalist[0].x.shape[0], device, config.use_weighted_loss\n",
    ")\n",
    "\n",
    "baseline_loss_mean_target = compute_baseline_of_mean_target(\n",
    "    dataset=train_dl, loss_fct=loss_fct, device=device, scalers=scalers_train\n",
    ")\n",
    "baseline_loss = compute_baseline_of_no_policies(\n",
    "    dataset=train_dl, loss_fct=loss_fct, device=device, scalers=scalers_train\n",
    ")\n",
    "print(\"baseline loss mean \" + str(baseline_loss_mean_target))\n",
    "print(\"baseline loss no  \" + str(baseline_loss))\n",
    "\n",
    "early_stopping = EarlyStopping(patience=params[\"early_stopping_patience\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 35,968\n",
      "Trainable parameters: 35,968\n",
      "Non-trainable parameters: 0\n",
      "\n",
      "Parameter breakdown by layer:\n",
      "blocks.0.signed_fusion_layer.lin_layer1.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.0.signed_fusion_layer.lin_layer2.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.0.unsigned_fusion_layer.lin_layer1.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.0.unsigned_fusion_layer.lin_layer1.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.0.unsigned_fusion_layer.lin_layer2.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.0.unsigned_fusion_layer.lin_layer2.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.0.unsigned_conv.lin.weight: 160 parameters, shape: torch.Size([32, 5])\n",
      "blocks.0.unsigned_conv.conv.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.0.unsigned_conv.conv.lin.weight: 160 parameters, shape: torch.Size([32, 5])\n",
      "blocks.0.unsigned_signed_conv.lin.weight: 160 parameters, shape: torch.Size([32, 5])\n",
      "blocks.0.signed_conv.lin.weight: 32 parameters, shape: torch.Size([32, 1])\n",
      "blocks.0.signed_conv.conv.lin.weight: 32 parameters, shape: torch.Size([32, 1])\n",
      "blocks.0.signed_unsigned_conv.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.0.signed_unsigned_conv.lin.weight: 32 parameters, shape: torch.Size([32, 1])\n",
      "blocks.1.signed_fusion_layer.lin_layer1.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.1.signed_fusion_layer.lin_layer2.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.1.unsigned_fusion_layer.lin_layer1.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.1.unsigned_fusion_layer.lin_layer1.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.1.unsigned_fusion_layer.lin_layer2.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.1.unsigned_fusion_layer.lin_layer2.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.1.unsigned_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.1.unsigned_conv.conv.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.1.unsigned_conv.conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.1.unsigned_signed_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.1.signed_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.1.signed_conv.conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.1.signed_unsigned_conv.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.1.signed_unsigned_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.2.signed_fusion_layer.lin_layer1.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.2.signed_fusion_layer.lin_layer2.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.2.unsigned_fusion_layer.lin_layer1.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.2.unsigned_fusion_layer.lin_layer1.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.2.unsigned_fusion_layer.lin_layer2.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.2.unsigned_fusion_layer.lin_layer2.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.2.unsigned_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.2.unsigned_conv.conv.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.2.unsigned_conv.conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.2.unsigned_signed_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.2.signed_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.2.signed_conv.conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.2.signed_unsigned_conv.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.2.signed_unsigned_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.3.signed_fusion_layer.lin_layer1.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.3.signed_fusion_layer.lin_layer2.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.3.unsigned_fusion_layer.lin_layer1.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.3.unsigned_fusion_layer.lin_layer1.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.3.unsigned_fusion_layer.lin_layer2.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.3.unsigned_fusion_layer.lin_layer2.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.3.unsigned_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.3.unsigned_conv.conv.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.3.unsigned_conv.conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.3.unsigned_signed_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.3.signed_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.3.signed_conv.conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "blocks.3.signed_unsigned_conv.bias: 32 parameters, shape: torch.Size([32])\n",
      "blocks.3.signed_unsigned_conv.lin.weight: 1,024 parameters, shape: torch.Size([32, 32])\n",
      "signed_head.weight: 32 parameters, shape: torch.Size([1, 32])\n",
      "unsigned_head.weight: 32 parameters, shape: torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "# Count and print the number of parameters in the model\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")\n",
    "\n",
    "# Print parameter breakdown by layer\n",
    "print(\"\\nParameter breakdown by layer:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel():,} parameters, shape: {param.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 499/499 [01:18<00:00,  6.37it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, validation loss: 3.869412457689326, lr: 0.00019959919839679358, r^2: 0.018782854080200195\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 3.869412457689326\n",
      "Checkpoint saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/checkpoints/checkpoint_epoch_0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 499/499 [01:18<00:00,  6.35it/s]\n",
      "Epoch 2/100: 100%|██████████| 499/499 [01:18<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, validation loss: 2.5360361109388636, lr: 0.0003995991983967936, r^2: 0.35947632789611816\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 2.5360361109388636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 499/499 [01:17<00:00,  6.46it/s]\n",
      "Epoch 3/100: 100%|██████████| 499/499 [01:17<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, validation loss: 2.1454220781935023, lr: 0.0005995991983967936, r^2: 0.4582584500312805\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 2.1454220781935023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 499/499 [01:17<00:00,  6.44it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, validation loss: 1.9038724442745776, lr: 0.0007995991983967936, r^2: 0.5202885866165161\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 1.9038724442745776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 499/499 [01:17<00:00,  6.41it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, validation loss: 1.7652639017460194, lr: 0.0009995991983967937, r^2: 0.5534452199935913\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 1.7652639017460194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 499/499 [01:17<00:00,  6.43it/s]\n",
      "Epoch 6/100: 100%|██████████| 499/499 [01:17<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, validation loss: 1.6707858037441334, lr: 0.0009997304459184093, r^2: 0.5786421298980713\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 1.6707858037441334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 499/499 [01:17<00:00,  6.41it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, validation loss: 1.5998551528504554, lr: 0.0009989199124447589, r^2: 0.5967550277709961\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 1.5998551528504554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 499/499 [01:17<00:00,  6.43it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, validation loss: 1.5158839923270204, lr: 0.0009975692847985092, r^2: 0.6173065304756165\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 1.5158839923270204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 499/499 [01:17<00:00,  6.40it/s]\n",
      "Epoch 9/100: 100%|██████████| 499/499 [01:17<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, validation loss: 1.471365603994816, lr: 0.0009956800398711614, r^2: 0.6283063888549805\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 1.471365603994816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 499/499 [01:18<00:00,  6.37it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, validation loss: 1.4336389214434522, lr: 0.0009932542435243065, r^2: 0.6375834941864014\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 1.4336389214434522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 499/499 [01:17<00:00,  6.41it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, validation loss: 1.4222131067133965, lr: 0.0009902945483306342, r^2: 0.6405092477798462\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 1.4222131067133965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 499/499 [01:17<00:00,  6.43it/s]\n",
      "Epoch 12/100: 100%|██████████| 499/499 [01:17<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11, validation loss: 1.343320298068067, lr: 0.0009868041906733853, r^2: 0.66117924451828\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 1.343320298068067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 499/499 [01:17<00:00,  6.42it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12, validation loss: 1.323764144106114, lr: 0.0009827869872074126, r^2: 0.6660875082015991\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 1.323764144106114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 499/499 [01:17<00:00,  6.44it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13, validation loss: 1.3044337972681572, lr: 0.0009782473306857266, r^2: 0.6705885529518127\n",
      "Best model saved to /home/dnguyen/gnn_predicting_effects_of_traffic_policies/data/IDP/eign/trained_model/model.pth with validation loss: 1.3044337972681572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100:  20%|██        | 102/499 [00:15<01:00,  6.51it/s]"
     ]
    }
   ],
   "source": [
    "best_val_loss, best_epoch = gnn_instance.train_model(\n",
    "    config=config,\n",
    "    loss_fct=loss_fct,\n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=1e-4),\n",
    "    train_dl=train_dl,\n",
    "    valid_dl=valid_dl,\n",
    "    device=device,\n",
    "    early_stopping=early_stopping,\n",
    "    model_save_path=model_save_path,\n",
    "    scalers_train=scalers_train,\n",
    "    scalers_validation=scalers_validation,\n",
    "    use_signed=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Best model saved to {model_save_path} with validation loss: {best_val_loss} at epoch {best_epoch}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
