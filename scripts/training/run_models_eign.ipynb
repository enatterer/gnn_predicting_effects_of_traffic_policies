{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used for debugging. Should have the same functionality as run_models.py, but with more verbose output.\n",
    "\n",
    "**[TODO]** Update from run_models.py when the dust settles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "# Add the 'scripts' directory to Python Path\n",
    "scripts_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "from training.help_functions import *\n",
    "\n",
    "from gnn.help_functions import EIGN_Loss, compute_baseline_of_mean_target, compute_baseline_of_no_policies\n",
    "from gnn.models.point_net_transf_gat import PointNetTransfGAT\n",
    "from gnn.models.eign import EIGNLaplacianConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "\n",
    "# Please adjust as needed\n",
    "dataset_path = os.path.join(\n",
    "    project_root, \"data\", \"train_data\", \"edge_features_with_net_flow\"\n",
    ")\n",
    "base_dir = os.path.join(project_root, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS = [\n",
    "    \"project_name\",\n",
    "    \"predict_mode_stats\",\n",
    "    \"in_channels\",\n",
    "    \"use_all_features\",\n",
    "    \"out_channels\",\n",
    "    \"loss_fct\",\n",
    "    \"use_weighted_loss\",\n",
    "    \"point_net_conv_layer_structure_local_mlp\",\n",
    "    \"point_net_conv_layer_structure_global_mlp\",\n",
    "    \"gat_conv_layer_structure\",\n",
    "    \"use_bootstrapping\",\n",
    "    \"num_epochs\",\n",
    "    \"batch_size\",\n",
    "    \"lr\",\n",
    "    \"early_stopping_patience\",\n",
    "    \"use_dropout\",\n",
    "    \"dropout\",\n",
    "    \"gradient_accumulation_steps\",\n",
    "    \"use_gradient_clipping\",\n",
    "    \"device_nr\",\n",
    "    \"unique_model_description\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_parameters(args):\n",
    "\n",
    "    params = {\n",
    "        # KEEP IN MIND: IF WE CHANGE PARAMETERS, WE NEED TO CHANGE THE NAME OF THE RUN IN WANDB (for the config)\n",
    "        \"project_name\": \"IDP\",\n",
    "        \"predict_mode_stats\": args.predict_mode_stats,\n",
    "        \"in_channels\": args.in_channels,\n",
    "        \"use_all_features\": args.use_all_features,\n",
    "        \"out_channels\": args.out_channels,\n",
    "        \"loss_fct\": args.loss_fct,\n",
    "        \"use_weighted_loss\": args.use_weighted_loss,\n",
    "        \"point_net_conv_layer_structure_local_mlp\": [\n",
    "            int(x) for x in args.point_net_conv_layer_structure_local_mlp.split(\",\")\n",
    "        ],\n",
    "        \"point_net_conv_layer_structure_global_mlp\": [\n",
    "            int(x) for x in args.point_net_conv_layer_structure_global_mlp.split(\",\")\n",
    "        ],\n",
    "        \"gat_conv_layer_structure\": [\n",
    "            int(x) for x in args.gat_conv_layer_structure.split(\",\")\n",
    "        ],\n",
    "        \"use_bootstrapping\": args.use_bootstrapping,\n",
    "        \"num_epochs\": args.num_epochs,\n",
    "        \"batch_size\": int(args.batch_size),\n",
    "        \"lr\": float(args.lr),\n",
    "        \"early_stopping_patience\": args.early_stopping_patience,\n",
    "        \"use_dropout\": args.use_dropout,\n",
    "        \"dropout\": args.dropout,\n",
    "        \"gradient_accumulation_steps\": args.gradient_accumulation_steps,\n",
    "        \"use_gradient_clipping\": args.use_gradient_clipping,\n",
    "        \"device_nr\": args.device_nr,\n",
    "    }\n",
    "\n",
    "    params[\"unique_model_description\"] = \"eign\"\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch number: 1\n",
      "Processing batch number: 2\n",
      "Processing batch number: 3\n",
      "Loaded 1000 items into datalist\n"
     ]
    }
   ],
   "source": [
    "datalist = []\n",
    "batch_num = 1\n",
    "while True:  # Change this to \"and batch_num < 10\" for a faster run\n",
    "    print(f\"Processing batch number: {batch_num}\")\n",
    "    # total_memory, available_memory, used_memory = get_memory_info()\n",
    "    # print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "    # print(f\"Available Memory: {available_memory:.2f} GB\")\n",
    "    # print(f\"Used Memory: {used_memory:.2f} GB\")\n",
    "    batch_file = os.path.join(dataset_path, f\"datalist_batch_{batch_num}.pt\")\n",
    "    if not os.path.exists(batch_file):\n",
    "        break\n",
    "    batch_data = torch.load(batch_file, map_location=\"cpu\")\n",
    "    if isinstance(batch_data, list):\n",
    "        datalist.extend(batch_data)\n",
    "    batch_num += 1\n",
    "print(f\"Loaded {len(datalist)} items into datalist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the argparse section with this:\n",
    "args = {\n",
    "    \"in_channels\": 5,\n",
    "    \"use_all_features\": False,\n",
    "    \"out_channels\": 1,\n",
    "    \"loss_fct\": \"mse\",\n",
    "    \"use_weighted_loss\": True,\n",
    "    \"predict_mode_stats\": False,\n",
    "    \"point_net_conv_layer_structure_local_mlp\": \"256\",\n",
    "    \"point_net_conv_layer_structure_global_mlp\": \"512\",\n",
    "    \"gat_conv_layer_structure\": \"128,256,512,256\",\n",
    "    \"use_bootstrapping\": False,\n",
    "    \"num_epochs\": 50,\n",
    "    \"batch_size\": 8,\n",
    "    \"lr\": 0.001,\n",
    "    \"early_stopping_patience\": 5,\n",
    "    \"use_dropout\": True,\n",
    "    \"dropout\": 0.3,\n",
    "    \"gradient_accumulation_steps\": 3,\n",
    "    \"use_gradient_clipping\": True,\n",
    "    \"lr_scheduler_warmup_steps\": 10000,\n",
    "    \"device_nr\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "# Convert the dictionary to an object with attributes\n",
    "class Args:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "\n",
    "args = Args(**args)\n",
    "set_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0 with CUDA_VISIBLE_DEVICES=0\n",
      "Starting prepare_data_with_graph_features with 1000 items\n",
      "Splitting into subsets...\n",
      "Total dataset length: 1000\n",
      "Training subset length: 800\n",
      "Validation subset length: 150\n",
      "Test subset length: 50\n",
      "Split complete. Train: 800, Valid: 150, Test: 50\n",
      "Normalizing train set...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 8/8 [00:01<00:00,  4.79it/s]\n",
      "Normalizing x features: 100%|██████████| 8/8 [00:00<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n",
      "Fitting and normalizing pos features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "Normalizing pos features: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos features normalized\n",
      "Train set normalized\n",
      "Normalizing validation set...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 2/2 [00:00<00:00,  6.54it/s]\n",
      "Normalizing x features: 100%|██████████| 2/2 [00:00<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n",
      "Fitting and normalizing pos features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n",
      "Normalizing pos features: 100%|██████████| 1/1 [00:00<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos features normalized\n",
      "Validation set normalized\n",
      "Normalizing test set...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s]\n",
      "Normalizing x features: 100%|██████████| 1/1 [00:00<00:00, 18.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n",
      "Fitting and normalizing pos features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00,  9.30it/s]\n",
      "Normalizing pos features: 100%|██████████| 1/1 [00:00<00:00, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos features normalized\n",
      "Test set normalized\n",
      "Creating train loader...\n",
      "Train loader created\n",
      "Creating validation loader...\n",
      "Validation loader created\n",
      "Creating test loader...\n",
      "Test loader created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders and scalers saved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:6pp2rcrt) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e8565d6ff4403fbf349088eb23850d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wannabe_best_6</strong> at: <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/runs_04_2025/runs/6pp2rcrt' target=\"_blank\">https://wandb.ai/thuaduc24042001-technical-university-of-munich/runs_04_2025/runs/6pp2rcrt</a><br/> View project at: <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/runs_04_2025' target=\"_blank\">https://wandb.ai/thuaduc24042001-technical-university-of-munich/runs_04_2025</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250519_164547-6pp2rcrt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:6pp2rcrt). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610f135a2e40408281bf0e3a28606538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112785433336587, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/duc-nguyen/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/training/wandb/run-20250519_164658-6r5q2pl8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP/runs/6r5q2pl8' target=\"_blank\">eign</a></strong> to <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP' target=\"_blank\">https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP/runs/6r5q2pl8' target=\"_blank\">https://wandb.ai/thuaduc24042001-technical-university-of-munich/IDP/runs/6r5q2pl8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 286, in check_stop_status\n",
      "    self._loop_check_status(\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
      "    local_handle = request()\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 840, in deliver_stop_status\n",
      "    return self._deliver_stop_status(status)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 494, in _deliver_stop_status\n",
      "    return self._deliver_record(record)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n",
      "Exception in thread NetStatThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
      "    self.run()\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    interface._publish(record)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 268, in check_network_status\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._loop_check_status(\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
      "    self._send_message(msg)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    local_handle = request()\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 848, in deliver_network_status\n",
      "Exception in thread IntMsgThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    self.run()\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 300, in check_internal_messages\n",
      "    return self._deliver_network_status(status)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 510, in _deliver_network_status\n",
      "    self._loop_check_status(\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 224, in _loop_check_status\n",
      "    local_handle = request()\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 856, in deliver_internal_messages\n",
      "    return self._deliver_record(record)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
      "    return self._deliver_internal_messages(internal_message)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 516, in _deliver_internal_messages\n",
      "    return self._deliver_record(record)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 459, in _deliver_record\n",
      "    interface._publish(record)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    interface._publish(record)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    self._send_message(msg)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    self.send_server_request(server_req)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    self._send_message(msg)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"/home/duc-nguyen/miniconda3/envs/traffic/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "gpus = get_available_gpus()\n",
    "best_gpu = select_best_gpu(gpus)\n",
    "set_cuda_visible_device(best_gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "params = get_parameters(args)\n",
    "\n",
    "# Create directory for the run\n",
    "unique_run_dir = os.path.join(\n",
    "    base_dir, params[\"project_name\"], params[\"unique_model_description\"]\n",
    ")\n",
    "os.makedirs(unique_run_dir, exist_ok=True)\n",
    "\n",
    "model_save_path, path_to_save_dataloader = get_paths(\n",
    "    base_dir=os.path.join(base_dir, params[\"project_name\"]),\n",
    "    unique_model_description=params[\"unique_model_description\"],\n",
    "    model_save_path=\"trained_model/model.pth\",\n",
    ")\n",
    "train_dl, valid_dl, scalers_train, scalers_validation = (\n",
    "    prepare_data_with_graph_features(\n",
    "        datalist=datalist,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        path_to_save_dataloader=path_to_save_dataloader,\n",
    "        use_all_features=params[\"use_all_features\"],\n",
    "        use_bootstrapping=params[\"use_bootstrapping\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "config = setup_wandb({param: params[param] for param in PARAMETERS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(architecture: str, config: object, device: torch.device):\n",
    "    \"\"\"\n",
    "    Factory function to create the specified model architecture.\n",
    "\n",
    "    Parameters:\n",
    "    - architecture: str, the name of the architecture to use\n",
    "    - config: object containing model parameters\n",
    "    - device: torch device to put the model on\n",
    "\n",
    "    Returns:\n",
    "    - Initialized model on the specified device\n",
    "    \"\"\"\n",
    "    if architecture == \"point_net_transf_gat\":\n",
    "        return PointNetTransfGAT(\n",
    "            in_channels=config.in_channels,\n",
    "            out_channels=config.out_channels,\n",
    "            point_net_conv_layer_structure_local_mlp=config.point_net_conv_layer_structure_local_mlp,\n",
    "            point_net_conv_layer_structure_global_mlp=config.point_net_conv_layer_structure_global_mlp,\n",
    "            gat_conv_layer_structure=config.gat_conv_layer_structure,\n",
    "            use_dropout=config.use_dropout,\n",
    "            dropout=config.dropout,\n",
    "            predict_mode_stats=config.predict_mode_stats,\n",
    "            dtype=torch.float32,\n",
    "        ).to(device)\n",
    "    elif architecture == \"eign\":\n",
    "        # TO BE IMPLEMENTED\n",
    "        return EIGNLaplacianConv(\n",
    "            in_channels_signed=1,\n",
    "            out_channels_signed=1,\n",
    "            in_channels_unsigned=5,\n",
    "            out_channels_unsigned=1,\n",
    "            hidden_channels_signed=32,\n",
    "            hidden_channels_unsigned=32,\n",
    "            num_blocks=4,\n",
    "        ).to(device)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown architecture: {architecture}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline loss mean 114.22825622558594\n",
      "baseline loss no  114.3958511352539\n"
     ]
    }
   ],
   "source": [
    "gnn_instance = create_model(\"eign\", config, device)\n",
    "\n",
    "model = gnn_instance.to(device)\n",
    "loss_fct = EIGN_Loss(config.loss_fct, datalist[0].x.shape[0], device)\n",
    "\n",
    "baseline_loss_mean_target = compute_baseline_of_mean_target(\n",
    "    dataset=train_dl, loss_fct=loss_fct, device=device, scalers=scalers_train\n",
    ")\n",
    "baseline_loss = compute_baseline_of_no_policies(\n",
    "    dataset=train_dl, loss_fct=loss_fct, device=device, scalers=scalers_train\n",
    ")\n",
    "print(\"baseline loss mean \" + str(baseline_loss_mean_target))\n",
    "print(\"baseline loss no  \" + str(baseline_loss))\n",
    "\n",
    "early_stopping = EarlyStopping(patience=params[\"early_stopping_patience\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   1%|          | 1/100 [00:00<00:40,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_signed:  torch.Size([253080, 1])\n",
      "targets_node_predictions_signed:  torch.Size([253080, 1])\n",
      "predicted_unsigned:  torch.Size([253080, 1])\n",
      "targets_node_predictions_unsigned:  torch.Size([253080, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   2%|▏         | 2/100 [00:00<00:36,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_signed:  torch.Size([253080, 1])\n",
      "targets_node_predictions_signed:  torch.Size([253080, 1])\n",
      "predicted_unsigned:  torch.Size([253080, 1])\n",
      "targets_node_predictions_unsigned:  torch.Size([253080, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   3%|▎         | 3/100 [00:01<00:35,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_signed:  torch.Size([253080, 1])\n",
      "targets_node_predictions_signed:  torch.Size([253080, 1])\n",
      "predicted_unsigned:  torch.Size([253080, 1])\n",
      "targets_node_predictions_unsigned:  torch.Size([253080, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   3%|▎         | 3/100 [00:01<00:37,  2.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_val_loss, best_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mgnn_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscalers_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalers_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscalers_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalers_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_save_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with validation loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/gnn/models/eign.py:247\u001b[0m, in \u001b[0;36mEIGN.train_model\u001b[0;34m(self, config, loss_fct, optimizer, train_dl, valid_dl, device, early_stopping, model_save_path, scalers_train, scalers_validation)\u001b[0m\n\u001b[1;32m    241\u001b[0m x_unsigned \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# print(f\"epoch: {epoch}\")\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# print(f\"eign x_signed: {x_signed.shape}\")\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# print(f\"eign x_unsigned: {x_unsigned.shape}\\n\")\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m eign_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_signed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_signed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_unsigned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_unsigned\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_directed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_is_directed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m predicted_signed, predicted_unsigned \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    254\u001b[0m     eign_output\u001b[38;5;241m.\u001b[39msigned,\n\u001b[1;32m    255\u001b[0m     eign_output\u001b[38;5;241m.\u001b[39munsigned,\n\u001b[1;32m    256\u001b[0m )\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Ensure predictions and targets are float32\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/gnn/models/eign.py:138\u001b[0m, in \u001b[0;36mEIGN.forward\u001b[0;34m(self, x_signed, x_unsigned, edge_index, is_directed, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     x_unsigned \u001b[38;5;241m=\u001b[39m x_unsigned\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 138\u001b[0m     x_signed, x_unsigned \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_signed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_signed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_unsigned\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_unsigned\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_directed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_directed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x_signed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         x_signed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigned_activation_fn(x_signed)\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/gnn/models/block/block.py:219\u001b[0m, in \u001b[0;36mEIGNBlock.forward\u001b[0;34m(self, x_signed, x_unsigned, edge_index, is_directed)\u001b[0m\n\u001b[1;32m    213\u001b[0m     h_unsigned_unsigned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munsigned_conv(\n\u001b[1;32m    214\u001b[0m         edge_index\u001b[38;5;241m=\u001b[39medge_index,\n\u001b[1;32m    215\u001b[0m         x\u001b[38;5;241m=\u001b[39mx_unsigned,\n\u001b[1;32m    216\u001b[0m         is_directed\u001b[38;5;241m=\u001b[39mis_directed,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_unsigned_to_signed_conv:\n\u001b[0;32m--> 219\u001b[0m         h_unsigned_signed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsigned_signed_conv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m            \u001b[49m\u001b[43medge_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_unsigned\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_directed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_directed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Mixing and activation\u001b[39;00m\n\u001b[1;32m    226\u001b[0m h_signed_signed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mix(h_signed_signed, h_unsigned_signed)\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/gnn/models/conv/laplacian.py:80\u001b[0m, in \u001b[0;36mMagneticEdgeLaplacianConv.forward\u001b[0;34m(self, x, edge_index, is_directed)\u001b[0m\n\u001b[1;32m     71\u001b[0m laplacian \u001b[38;5;241m=\u001b[39m magnetic_edge_laplacian(\n\u001b[1;32m     72\u001b[0m     edge_index,\n\u001b[1;32m     73\u001b[0m     is_directed,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     signed_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigned_out,\n\u001b[1;32m     78\u001b[0m )\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize:\n\u001b[0;32m---> 80\u001b[0m     laplacian \u001b[38;5;241m=\u001b[39m \u001b[43mdegree_normalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlaplacian\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_laplacian \u001b[38;5;241m=\u001b[39m laplacian\n",
      "File \u001b[0;32m~/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/gnn/models/laplacian.py:132\u001b[0m, in \u001b[0;36mdegree_normalization\u001b[0;34m(matrix, return_deg_inv_sqrt)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdegree_normalization\u001b[39m(\n\u001b[1;32m    121\u001b[0m     matrix: torch\u001b[38;5;241m.\u001b[39mTensor, return_deg_inv_sqrt: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    122\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    Normalizes the matrix based on the square roots of the out-degrees like GCN.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;124;03m        torch.Tensor: Degree normalized matrix.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     deg \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_dense()\n\u001b[1;32m    133\u001b[0m     deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    134\u001b[0m     deg_inv_sqrt[deg_inv_sqrt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_val_loss, best_epoch = gnn_instance.train_model(\n",
    "    config=config,\n",
    "    loss_fct=loss_fct,\n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=1e-4),\n",
    "    train_dl=train_dl,\n",
    "    valid_dl=valid_dl,\n",
    "    device=device,\n",
    "    early_stopping=early_stopping,\n",
    "    model_save_path=model_save_path,\n",
    "    scalers_train=scalers_train,\n",
    "    scalers_validation=scalers_validation,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Best model saved to {model_save_path} with validation loss: {best_val_loss} at epoch {best_epoch}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
