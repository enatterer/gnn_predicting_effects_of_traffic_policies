{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Add the 'scripts' directory to the Python path\n",
    "scripts_path = os.path.abspath(os.path.join('..'))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "    \n",
    "import joblib\n",
    "\n",
    "# Now you can import the gnn_io module\n",
    "import gnn_io as gio\n",
    "\n",
    "import gnn_architectures as garch\n",
    "# torch.set_printoptions(precision=4, sci_mode=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters \n",
    "project_name = \"test_different_parameters\"\n",
    "path_to_save_dataloader = \"../../data/data_created_during_training_needed_for_testing/\"\n",
    "\n",
    "loss_fct = torch.nn.MSELoss()\n",
    "early_stopping_patience = 10\n",
    "\n",
    "config={\n",
    "        \"epochs\": 1000,\n",
    "        \"batch_size\": 32,\n",
    "        \"lr\": 0.001,\n",
    "        \"loss_fct\": \"MSELoss\",\n",
    "        \"early_stopping_patience\": early_stopping_patience,\n",
    "        \"hidden_layer_size\": 32,\n",
    "        \"gat_layers\": 2,\n",
    "        \"gcn_layers\": 0,\n",
    "        \"output_layer\": 'gat',\n",
    "        \"in_channels\": 6, # dimensions of the x vector + 2 (pos)\n",
    "        \"out_channels\": 1,\n",
    "        # \"dropout\": 0.15,\n",
    "    }\n",
    "\n",
    "unique_model_description = f\"mse_loss_hidden_{config['hidden_layer_size']}_gat_{config['gat_layers']}_gcn_{config['gcn_layers']}_lr_{config['lr']}_batch_{config['batch_size']}_epochs_{config['epochs']}_early_{config['early_stopping_patience']}_out_{config['output_layer']}_\"\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_size': {'values': [16, 32, 64]},\n",
      " 'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
      " 'optimizer': {'values': ['adam', 'sgd']},\n",
      " 'parameters': {'batch_size': {'distribution': 'q_log_uniform_values',\n",
      "                               'max': 256,\n",
      "                               'min': 32,\n",
      "                               'q': 8},\n",
      "                'learning_rate': {'distribution': 'uniform',\n",
      "                                  'max': 0.1,\n",
      "                                  'min': 0}}}\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'learning_rate': {\n",
    "        # a flat distribution between 0 and 0.1\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0,\n",
    "        'max': 0.1\n",
    "        },\n",
    "    # 'batch_size': {\n",
    "    #     # integers between 32 and 256\n",
    "    #     # with evenly-distributed logarithms \n",
    "    #     'distribution': 'q_log_uniform_values',\n",
    "    #     'q': 8,\n",
    "    #     'min': 32,\n",
    "    #     'max': 256,\n",
    "    #   }\n",
    "    \n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'sgd']\n",
    "        },\n",
    "        'hidden_layer_size': {\n",
    "            'values': [16, 32, 64]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# # Fix some parameters over which we do not want to sweep\n",
    "# parameters_dict.update({\n",
    "#     'epochs': {\n",
    "#         'value': 1}\n",
    "#     })\n",
    "\n",
    "# # Add distributions for some parameters, not just randomly selecting any of the values\n",
    "# parameters_dict.update({\n",
    "    \n",
    "#     })\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the Data objects\n",
    "data_dict_list = torch.load('../../data/train_data/dataset_1pm_0-3100.pt')\n",
    "datalist = [Data(x=d['x'], edge_index=d['edge_index'], pos=d['pos'], y=d['y']) for d in data_dict_list]\n",
    "dataset = gio.normalize_dataset(datalist, y_scalar=None, x_scalar_list=None, pos_scalar=None, directory_path=path_to_save_dataloader)\n",
    "\n",
    "# baseline_error = gio.compute_baseline_of_no_policies(dataset=dataset, loss_fct=loss_fct)\n",
    "# print(f'Baseline error no policies: {baseline_error}')\n",
    "\n",
    "# baseline_error = gio.compute_baseline_of_mean_target(dataset=dataset, loss_fct=loss_fct)\n",
    "# print(f'Baseline error mean: {baseline_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400 response executing GraphQL.\n",
      "{\"errors\":[{\"message\":\"Invalid sweep config: Sweep config must contain parameters section\",\"path\":[\"upsertSweep\"]}],\"data\":{\"upsertSweep\":null}}\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: Invalid sweep config: Sweep config must contain parameters section (<Response [400]>)\n"
     ]
    },
    {
     "ename": "UsageError",
     "evalue": "Invalid sweep config: Sweep config must contain parameters section",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/sdk/lib/retry.py:131\u001b[0m, in \u001b[0;36mRetry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    132\u001b[0m     \u001b[39m# Only print resolved attempts once every minute\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/sdk/internal/internal_api.py:369\u001b[0m, in \u001b[0;36mApi.execute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 369\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mexecute(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py:52\u001b[0m, in \u001b[0;36mClient.execute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate(document)\n\u001b[0;32m---> 52\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_result(document, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39merrors:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py:60\u001b[0m, in \u001b[0;36mClient._get_result\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretries:\n\u001b[0;32m---> 60\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransport\u001b[39m.\u001b[39mexecute(document, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     62\u001b[0m last_exception \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/sdk/lib/gql_request.py:59\u001b[0m, in \u001b[0;36mGraphQLSession.execute\u001b[0;34m(self, document, variable_values, timeout)\u001b[0m\n\u001b[1;32m     58\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession\u001b[39m.\u001b[39mpost(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpost_args)\n\u001b[0;32m---> 59\u001b[0m request\u001b[39m.\u001b[39mraise_for_status()\n\u001b[1;32m     61\u001b[0m result \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api.wandb.ai/graphql",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUsageError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m early_stopping \u001b[39m=\u001b[39m gio\u001b[39m.\u001b[39mEarlyStopping(patience\u001b[39m=\u001b[39mearly_stopping_patience, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# gnn_instance = garch.MyGnn(in_channels=config['in_channels'], out_channels=config['out_channels'], hidden_size=config['hidden_layer_size'], gat_layers=config['gat_layers'], gcn_layers=config['gcn_layers'], output_layer=config['output_layer'])\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# model = gnn_instance.to(device)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m sweep_id \u001b[39m=\u001b[39m wandb\u001b[39m.\u001b[39msweep(sweep_config, project\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpytorch-sweeps-demo\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m():\n\u001b[1;32m     10\u001b[0m     wandb\u001b[39m.\u001b[39minit(\n\u001b[1;32m     11\u001b[0m     project\u001b[39m=\u001b[39mproject_name,\n\u001b[1;32m     12\u001b[0m     config \u001b[39m=\u001b[39m config)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/sdk/wandb_sweep.py:81\u001b[0m, in \u001b[0;36msweep\u001b[0;34m(sweep, entity, project)\u001b[0m\n\u001b[1;32m     79\u001b[0m     wandb_login\u001b[39m.\u001b[39m_login(_silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     80\u001b[0m api \u001b[39m=\u001b[39m InternalApi()\n\u001b[0;32m---> 81\u001b[0m sweep_id, warnings \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39mupsert_sweep(sweep)\n\u001b[1;32m     82\u001b[0m handle_sweep_config_violations(warnings)\n\u001b[1;32m     83\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCreate sweep with ID:\u001b[39m\u001b[39m\"\u001b[39m, sweep_id)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/apis/internal.py:129\u001b[0m, in \u001b[0;36mApi.upsert_sweep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupsert_sweep\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mupsert_sweep(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/apis/normalize.py:73\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[39mraise\u001b[39;00m CommError(message, err\u001b[39m.\u001b[39mlast_exception)\u001b[39m.\u001b[39mwith_traceback(\n\u001b[1;32m     70\u001b[0m             sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n\u001b[1;32m     71\u001b[0m         )\n\u001b[1;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m Error \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m     74\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m     75\u001b[0m     \u001b[39m# gql raises server errors with dict's as strings...\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(err\u001b[39m.\u001b[39margs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/apis/normalize.py:41\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhoa, you found a bug.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     42\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m     43\u001b[0m     errors \u001b[39m=\u001b[39m parse_backend_error_messages(error\u001b[39m.\u001b[39mresponse)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/sdk/internal/internal_api.py:3171\u001b[0m, in \u001b[0;36mApi.upsert_sweep\u001b[0;34m(self, config, controller, launch_scheduler, scheduler, obj_id, project, entity, state)\u001b[0m\n\u001b[1;32m   3165\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgql(\n\u001b[1;32m   3166\u001b[0m         mutation,\n\u001b[1;32m   3167\u001b[0m         variable_values\u001b[39m=\u001b[39mvariables,\n\u001b[1;32m   3168\u001b[0m         check_retry_fn\u001b[39m=\u001b[39mutil\u001b[39m.\u001b[39mno_retry_4xx,\n\u001b[1;32m   3169\u001b[0m     )\n\u001b[1;32m   3170\u001b[0m \u001b[39mexcept\u001b[39;00m UsageError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3171\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m   3172\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   3173\u001b[0m     \u001b[39m# graphql schema exception is generic\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m     err \u001b[39m=\u001b[39m e\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/sdk/internal/internal_api.py:3165\u001b[0m, in \u001b[0;36mApi.upsert_sweep\u001b[0;34m(self, config, controller, launch_scheduler, scheduler, obj_id, project, entity, state)\u001b[0m\n\u001b[1;32m   3162\u001b[0m     \u001b[39mif\u001b[39;00m state:\n\u001b[1;32m   3163\u001b[0m         variables[\u001b[39m\"\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m state\n\u001b[0;32m-> 3165\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgql(\n\u001b[1;32m   3166\u001b[0m         mutation,\n\u001b[1;32m   3167\u001b[0m         variable_values\u001b[39m=\u001b[39mvariables,\n\u001b[1;32m   3168\u001b[0m         check_retry_fn\u001b[39m=\u001b[39mutil\u001b[39m.\u001b[39mno_retry_4xx,\n\u001b[1;32m   3169\u001b[0m     )\n\u001b[1;32m   3170\u001b[0m \u001b[39mexcept\u001b[39;00m UsageError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   3171\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/sdk/internal/internal_api.py:341\u001b[0m, in \u001b[0;36mApi.gql\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgql\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 341\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retry_gql(\n\u001b[1;32m    342\u001b[0m         \u001b[39m*\u001b[39margs,\n\u001b[1;32m    343\u001b[0m         retry_cancel_event\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39mcancel_event,\n\u001b[1;32m    344\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    345\u001b[0m     )\n\u001b[1;32m    346\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/sdk/lib/retry.py:147\u001b[0m, in \u001b[0;36mRetry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retryable_exceptions \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    146\u001b[0m     \u001b[39m# if the secondary check fails, re-raise\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     retry_timedelta_triggered \u001b[39m=\u001b[39m check_retry_fn(e)\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m retry_timedelta_triggered:\n\u001b[1;32m    149\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_env/lib/python3.12/site-packages/wandb/util.py:881\u001b[0m, in \u001b[0;36mno_retry_4xx\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    880\u001b[0m body \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(e\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mcontent)\n\u001b[0;32m--> 881\u001b[0m \u001b[39mraise\u001b[39;00m UsageError(body[\u001b[39m\"\u001b[39m\u001b[39merrors\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mUsageError\u001b[0m: Invalid sweep config: Sweep config must contain parameters section"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "early_stopping = gio.EarlyStopping(patience=early_stopping_patience, verbose=True)\n",
    "# gnn_instance = garch.MyGnn(in_channels=config['in_channels'], out_channels=config['out_channels'], hidden_size=config['hidden_layer_size'], gat_layers=config['gat_layers'], gcn_layers=config['gcn_layers'], output_layer=config['output_layer'])\n",
    "# model = gnn_instance.to(device)\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"pytorch-sweeps-demo\")\n",
    "\n",
    "def train():\n",
    "    wandb.init(\n",
    "    project=project_name,\n",
    "    config = config)\n",
    "    \n",
    "    config = wandb.config\n",
    "    \n",
    "    gnn_instance = garch.MyGnn(in_channels=config['in_channels'], out_channels=config['out_channels'], hidden_size=config['hidden_layer_size'], gat_layers=config['gat_layers'], gcn_layers=config['gcn_layers'], output_layer=config['output_layer'])\n",
    "    model = gnn_instance.to(device)     \n",
    "    wandb.watch(model)\n",
    "\n",
    "    train_dl, valid_dl, test_dl = gio.create_dataloaders(batch_size = config['batch_size'], dataset=dataset, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "    # gio.save_dataloader(test_dl, path_to_save_dataloader + 'test_dl_' + unique_model_description + '.pt')\n",
    "    # gio.save_dataloader_params(test_dl, path_to_save_dataloader + 'test_loader_params_' + unique_model_description+ '.json')\n",
    "    garch.train(model, config=config, \n",
    "                                loss_fct=loss_fct, \n",
    "                                optimizer=torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=0.0),\n",
    "                                train_dl=train_dl, valid_dl=valid_dl,\n",
    "                                device=device, early_stopping=early_stopping)\n",
    "        \n",
    "\n",
    "wandb.agent(sweep_id=sweep_id, function=train, count=5)\n",
    "\n",
    "# best_val_loss, best_epoch = garch.train(model, config=config, \n",
    "#                                 loss_fct=loss_fct, \n",
    "#                                 optimizer=torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=0.0),\n",
    "#                                 train_dl=train_dl, valid_dl=valid_dl,\n",
    "#                                 device=device, early_stopping=early_stopping)\n",
    "\n",
    "# model.to_onnx(path_to_save_dataloader + 'model_' + unique_model_description + '.onnx', test_dl, device)\n",
    "# wandb.save(path_to_save_dataloader + 'model_' + unique_model_description + '.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
