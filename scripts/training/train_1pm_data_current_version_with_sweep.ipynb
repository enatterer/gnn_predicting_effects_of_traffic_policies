{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "# Add the 'scripts' directory to the Python path\n",
    "scripts_path = os.path.abspath(os.path.join('..'))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "import gnn_io as gio\n",
    "import gnn_architectures as garch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters \n",
    "project_name = \"test_different_parameters\"\n",
    "path_to_save_dataloader = \"../../data/data_created_during_training_needed_for_testing/\"\n",
    "\n",
    "loss_fct = torch.nn.MSELoss()\n",
    "early_stopping_patience = 10\n",
    "\n",
    "base_config={\n",
    "        \"epochs\": 1000,\n",
    "        \"batch_size\": 16,\n",
    "        \"output_layer\": 'gat',\n",
    "        \"in_channels\": 6, # dimensions of the x vector + 2 (pos)\n",
    "        \"out_channels\": 1,\n",
    "        \"early_stopping_patience\": early_stopping_patience,\n",
    "        \"learning_rate\": 0.001\n",
    "    }\n",
    "\n",
    "# unique_model_description = ''\n",
    "\n",
    "# Ensure deterministic behavior\n",
    "torch.backends.cudnn.deterministic = True\n",
    "random.seed(hash(\"setting random seeds\") % 2**32 - 1)\n",
    "np.random.seed(hash(\"improves reproducibility\") % 2**32 - 1)\n",
    "torch.manual_seed(hash(\"by removing stochasticity\") % 2**32 - 1)\n",
    "torch.cuda.manual_seed_all(hash(\"so runs are repeatable\") % 2**32 - 1)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'random',\n",
      " 'metric': {'goal': 'minimize', 'name': 'val_loss'},\n",
      " 'parameters': {'gat_layers': {'values': [0, 1, 2]},\n",
      "                'gcn_layers': {'values': [0, 1]},\n",
      "                'hidden_layer_size': {'values': [16, 32, 64]},\n",
      "                'optimizer': {'values': ['adam', 'sgd']}}}\n"
     ]
    }
   ],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'optimizer': {\n",
    "            'values': ['adam', 'sgd']\n",
    "        },\n",
    "        'hidden_layer_size': {\n",
    "            'values': [16, 32, 64]\n",
    "        },\n",
    "        'gat_layers':{\n",
    "            'values': [0, 1, 2]\n",
    "        },\n",
    "        'gcn_layers': {\n",
    "            'values': [0, 1]\n",
    "        }\n",
    "        # 'learning_rate': {\n",
    "        #     'distribution': 'uniform',\n",
    "        #     'min': 0,\n",
    "        #     'max': 0.1\n",
    "        # },\n",
    "    }\n",
    "}\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(sweep_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the Data objects\n",
    "data_dict_list = torch.load('../../data/train_data/dataset_1pm_0-3100.pt')\n",
    "datalist = [Data(x=d['x'], edge_index=d['edge_index'], pos=d['pos'], y=d['y']) for d in data_dict_list]\n",
    "dataset = gio.normalize_dataset(datalist, y_scalar=None, x_scalar_list=None, pos_scalar=None, directory_path=path_to_save_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    wandb.init(\n",
    "    project=project_name, config = base_config)\n",
    "    config = wandb.config\n",
    "    \n",
    "    # Initialize model with parameters from config\n",
    "    gnn_instance = garch.MyGnn(\n",
    "        in_channels=config.in_channels, \n",
    "        out_channels=config.out_channels, \n",
    "        hidden_size=config.hidden_layer_size, \n",
    "        gat_layers=config.gat_layers, \n",
    "        gcn_layers=config.gcn_layers, \n",
    "        output_layer=config.output_layer\n",
    "    )\n",
    "    model = gnn_instance.to(device)\n",
    "    wandb.watch(model)\n",
    "\n",
    "    \n",
    "    if config.optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    train_dl, valid_dl, test_dl = gio.create_dataloaders(batch_size = config.batch_size, dataset=dataset, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "    garch.train(model, config=config, loss_fct=loss_fct, \n",
    "                                optimizer=optimizer,\n",
    "                                train_dl=train_dl, valid_dl=valid_dl,\n",
    "                                device=device, early_stopping=gio.EarlyStopping(patience=early_stopping_patience, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menatterer\u001b[0m (\u001b[33mtum-traffic-engineering\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: dxzzevf1\n",
      "Sweep URL: https://wandb.ai/tum-traffic-engineering/pytorch-sweeps-demo/sweeps/dxzzevf1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: koqcnv3y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgat_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tgcn_layers: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/elenanatterer/Development/gnn_predicting_effects_of_traffic_policies/scripts/training/wandb/run-20240718_124823-koqcnv3y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/pytorch-sweeps-demo/runs/koqcnv3y' target=\"_blank\">cosmic-sweep-1</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/pytorch-sweeps-demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/tum-traffic-engineering/pytorch-sweeps-demo/sweeps/dxzzevf1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/pytorch-sweeps-demo/sweeps/dxzzevf1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/pytorch-sweeps-demo' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/pytorch-sweeps-demo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tum-traffic-engineering/pytorch-sweeps-demo/sweeps/dxzzevf1' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/pytorch-sweeps-demo/sweeps/dxzzevf1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/pytorch-sweeps-demo/runs/koqcnv3y' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/pytorch-sweeps-demo/runs/koqcnv3y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized\n",
      "MyGnn(\n",
      "  (pointLayer): PointNetConv(local_nn=Sequential(\n",
      "    (0): Linear(in_features=6, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  ), global_nn=Sequential(\n",
      "    (0): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
      "  ))\n",
      "  (graph_layers): Sequential(\n",
      "    (0) - GATConv(32, 32, heads=1): x, edge_index -> x\n",
      "    (1) - ReLU(inplace=True): x -> x\n",
      "  )\n",
      "  (output_layer): GATConv(32, 1, heads=1)\n",
      ")\n",
      "Total dataset length: 3079\n",
      "Training subset length: 2155\n",
      "Validation subset length: 461\n",
      "Test subset length: 463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "135it [10:58,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, validation loss: 0.003258088370785117, R^2: -5.005572319030762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "135it [10:32,  4.68s/it]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"pytorch-sweeps-demo\")\n",
    "wandb.agent(sweep_id=sweep_id, function=train, count=5)\n",
    "\n",
    "# model.to_onnx(path_to_save_dataloader + 'model_' + unique_model_description + '.onnx', test_dl, device)\n",
    "# wandb.save(path_to_save_dataloader + 'model_' + unique_model_description + '.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
