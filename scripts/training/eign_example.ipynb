{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EIGN: A universal model for edge-level problems\n",
    "\n",
    "Here, we will show you how to use the EIGN model for edge-level problems on a dummy graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Add the 'scripts' directory to Python Path\n",
    "scripts_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "from gnn.models import EIGNLaplacianConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dummy graph\n",
    "\n",
    "Let's create a dummy graph with some directed and undirected edges. We assign each edge with features that have an inherent direction (signed or orientation equivariant features) and some features that do not have an inherent direction (unsigned or orientation invariant features).\n",
    "\n",
    "The signed features are represented with respect to some arbitrary edge orientation through their sign. The edge orientation is encoded through the `edge_index`: If it contains an edge `(u, v)`, signed features are represented relative to the orientation `u -> v`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_index shape:  torch.Size([2, 7])\n",
      "edge_is_directed shape:  torch.Size([7])\n",
      "dummy_features_signed shape:  torch.Size([7, 3])\n",
      "dummy_features_unsigned shape:  torch.Size([7, 6])\n"
     ]
    }
   ],
   "source": [
    "num_signed_features = 3\n",
    "num_unsigned_features = 6\n",
    "\n",
    "# Represent the graph\n",
    "edge_index = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [0, 1],\n",
    "            [1, 2],\n",
    "            [2, 3],\n",
    "            [2, 4],\n",
    "            [3, 5],\n",
    "            [5, 0],\n",
    "            [5, 2],\n",
    "        ]\n",
    "    )\n",
    "    .t()\n",
    "    .contiguous()\n",
    ")\n",
    "edge_is_directed = torch.tensor([0, 0, 0, 0, 0, 1, 1], dtype=torch.bool)\n",
    "\n",
    "dummy_features_signed = torch.randn(edge_index.size(1), num_signed_features)\n",
    "dummy_features_unsigned = torch.randn(edge_index.size(1), num_unsigned_features)\n",
    "\n",
    "print(\"edge_index shape: \", edge_index.shape)\n",
    "print(\"edge_is_directed shape: \", edge_is_directed.shape)\n",
    "print(\"dummy_features_signed shape: \", dummy_features_signed.shape)\n",
    "print(\"dummy_features_unsigned shape: \", dummy_features_unsigned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the basic EIGN model\n",
    "\n",
    "We can create an instance of EIGN easily using the `eign` package. It produces both signed outputs (w.r.t. edge orientation) and unsigned outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EIGNLaplacianConv(\n",
    "    in_channels_signed=num_signed_features,\n",
    "    in_channels_unsigned=num_unsigned_features,\n",
    "    hidden_channels_signed=32,\n",
    "    hidden_channels_unsigned=32,\n",
    "    out_channels_signed=1,\n",
    "    out_channels_unsigned=5,\n",
    "    num_blocks=4,\n",
    "    q=1 / edge_index.size(1),\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/duc-nguyen/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/gnn/models/laplacian.py:112: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /opt/conda/conda-bld/pytorch_1704987280714/work/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  laplacian = (\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0643],\n",
       "         [-0.0115],\n",
       "         [ 0.0210],\n",
       "         [ 0.0391],\n",
       "         [-0.0548],\n",
       "         [ 0.0318],\n",
       "         [-0.0525]]),\n",
       " tensor([[ 0.0235, -0.0137,  0.0628, -0.0678, -0.0279],\n",
       "         [ 0.0302, -0.0128,  0.0689, -0.0073, -0.0288],\n",
       "         [ 0.0296,  0.0139,  0.0300, -0.0339, -0.0531],\n",
       "         [ 0.0077,  0.0005,  0.0266, -0.0123, -0.0308],\n",
       "         [-0.0129,  0.0477,  0.0293, -0.0811, -0.0122],\n",
       "         [ 0.0526,  0.0021,  0.0163, -0.1102,  0.0009],\n",
       "         [ 0.0371,  0.0047,  0.0137, -0.0590, -0.0031]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure edge_index is in the correct shape (2, num_edges)\n",
    "if edge_index.dim() != 2 or edge_index.size(0) != 2:\n",
    "    raise ValueError(\"edge_index must have shape [2, num_edges]\")\n",
    "\n",
    "# Ensure feature tensors match the expected dimensions\n",
    "if dummy_features_signed.size(1) != num_signed_features:\n",
    "    raise ValueError(\"dummy_features_signed must have the correct number of signed features\")\n",
    "if dummy_features_unsigned.size(1) != num_unsigned_features:\n",
    "    raise ValueError(\"dummy_features_unsigned must have the correct number of unsigned features\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        x_signed=dummy_features_signed,\n",
    "        x_unsigned=dummy_features_unsigned,\n",
    "        edge_index=edge_index,\n",
    "        is_directed=edge_is_directed,\n",
    "    )\n",
    "outputs.signed, outputs.unsigned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Orientation Equivariance and Invariance\n",
    "\n",
    "If we change the orientation of *undirected* edges, EIGN's outputs do not change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flip the orientation of edges 2 and 4\n",
    "orientation_flipped = torch.zeros(edge_index.size(1), dtype=torch.bool)\n",
    "orientation_flipped[2] = 1\n",
    "orientation_flipped[4] = 1\n",
    "\n",
    "edge_index_flipped = edge_index.clone()\n",
    "edge_index_flipped[:, orientation_flipped] = edge_index_flipped.flip(0)[\n",
    "    :, orientation_flipped\n",
    "]\n",
    "\n",
    "# Represent signed features in this new orientation\n",
    "dummy_features_signed_flipped = dummy_features_signed.clone()\n",
    "dummy_features_signed_flipped[orientation_flipped] = -dummy_features_signed_flipped[\n",
    "    orientation_flipped\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_flipped = model(\n",
    "        x_signed=dummy_features_signed_flipped,\n",
    "        x_unsigned=dummy_features_unsigned,\n",
    "        edge_index=edge_index_flipped,\n",
    "        is_directed=edge_is_directed,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsigned signals which are not represented relative to an orientation remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_flipped.unsigned - outputs.unsigned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Signed outputs also are not changed. However, since we changed the orientation of some edges, the sign of the corresponding signed signals have flipped. Intuitively, we have changed the basis in which signed signals are represented. This change is reflected through the sign in both EIGN's inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The signed outputs did not change as well, but are represented w.r.t. the new orientation\n",
    "outputs_flipped_signed_old_orientation = outputs_flipped.signed.clone()\n",
    "# If we reorient them back into the old orientation ...\n",
    "outputs_flipped_signed_old_orientation[\n",
    "    orientation_flipped\n",
    "] = -outputs_flipped_signed_old_orientation[orientation_flipped]\n",
    "# ... we get the same values\n",
    "outputs_flipped_signed_old_orientation - outputs.signed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we change the orientation (=direction) of a *directed* edge, EIGN is sensitive to that and outputs different signed and unsigned features. It can therefore learn to model the direction of directed edges and still represent signed and unsigned edge signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 2, 3, 5, 5],\n",
       "        [1, 2, 3, 4, 5, 0, 2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the orientation of a directed edge\n",
    "orientation_flipped_directed = torch.zeros(edge_index.size(1), dtype=torch.bool)\n",
    "orientation_flipped_directed[5] = 1\n",
    "\n",
    "edge_index_flipped_directed = edge_index.clone()\n",
    "edge_index_flipped_directed[:, orientation_flipped_directed] = (\n",
    "    edge_index_flipped_directed.flip(0)[:, orientation_flipped_directed]\n",
    ")\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent signed features in this new orientation\n",
    "\n",
    "dummy_features_signed_flipped_directed = dummy_features_signed.clone()\n",
    "dummy_features_signed_flipped_directed[\n",
    "    orientation_flipped_directed\n",
    "] = -dummy_features_signed_flipped_directed[orientation_flipped_directed]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_flipped_directed = model(\n",
    "        x_signed=dummy_features_signed_flipped_directed,\n",
    "        x_unsigned=dummy_features_unsigned,\n",
    "        edge_index=edge_index_flipped_directed,\n",
    "        is_directed=edge_is_directed,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0008, -0.0210,  0.0253,  0.0679, -0.0159],\n",
       "        [-0.0038,  0.0055,  0.0200,  0.0233,  0.0010],\n",
       "        [ 0.0067,  0.0043, -0.0079, -0.0135, -0.0073],\n",
       "        [ 0.0005,  0.0040, -0.0134, -0.0005,  0.0001],\n",
       "        [ 0.0023, -0.0253,  0.0008, -0.0034,  0.0146],\n",
       "        [-0.0004, -0.0620, -0.0011, -0.0101, -0.0218],\n",
       "        [-0.0002,  0.0022,  0.0176,  0.0004,  0.0192]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, the change in orientation (i.e. direction) of the edge breaks orientation invariance ...\n",
    "outputs.unsigned - outputs_flipped_directed.unsigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0200],\n",
       "        [-0.0165],\n",
       "        [-0.0182],\n",
       "        [-0.0018],\n",
       "        [ 0.0129],\n",
       "        [-0.0088],\n",
       "        [ 0.0197]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and also orientation equivariance (w.r.t the old orientation)\n",
    "outputs_flipped_directed_old_orientation = outputs_flipped_directed.signed.clone()\n",
    "outputs_flipped_directed_old_orientation[\n",
    "    orientation_flipped_directed\n",
    "] = -outputs_flipped_directed_old_orientation[orientation_flipped_directed]\n",
    "outputs_flipped_directed_old_orientation - outputs.signed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different variations of EIGN\n",
    "\n",
    "EIGN's Magnetic Laplacian operators also allow representing edge signals at the node level which further increases its expressivity (see our [paper](https://arxiv.org/pdf/2410.16935) for further reading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EIGNLaplacianWithNodeTransformationConv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mEIGNLaplacianWithNodeTransformationConv\u001b[49m(\n\u001b[1;32m      2\u001b[0m     in_channels_signed\u001b[38;5;241m=\u001b[39mnum_signed_features,\n\u001b[1;32m      3\u001b[0m     in_channels_unsigned\u001b[38;5;241m=\u001b[39mnum_unsigned_features,\n\u001b[1;32m      4\u001b[0m     hidden_channels_signed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      5\u001b[0m     hidden_channels_unsigned\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      6\u001b[0m     out_channels_signed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      7\u001b[0m     out_channels_unsigned\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m      8\u001b[0m     num_blocks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m      9\u001b[0m     q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     10\u001b[0m )\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EIGNLaplacianWithNodeTransformationConv' is not defined"
     ]
    }
   ],
   "source": [
    "model = EIGNLaplacianWithNodeTransformationConv(\n",
    "    in_channels_signed=num_signed_features,\n",
    "    in_channels_unsigned=num_unsigned_features,\n",
    "    hidden_channels_signed=32,\n",
    "    hidden_channels_unsigned=32,\n",
    "    out_channels_signed=1,\n",
    "    out_channels_unsigned=5,\n",
    "    num_blocks=4,\n",
    "    q=1 / edge_index.size(1),\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even define your own (learnable) mapping to transform node features that are induced by the Magnetic Edge Laplacian's boundary operators. By default, a `ReLU` is used to introduce some nonlinearity. You can use whatever you want, even a node-level GNN is possible here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_node_feature_transformation(\n",
    "    num_channels_in: int, num_channels_out: int\n",
    ") -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_channels_in, num_channels_out),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_channels_out, num_channels_out),\n",
    "    )\n",
    "\n",
    "\n",
    "model = EIGNLaplacianWithNodeTransformationConv(\n",
    "    in_channels_signed=num_signed_features,\n",
    "    in_channels_unsigned=num_unsigned_features,\n",
    "    hidden_channels_signed=32,\n",
    "    hidden_channels_unsigned=32,\n",
    "    out_channels_signed=1,\n",
    "    out_channels_unsigned=5,\n",
    "    num_blocks=4,\n",
    "    q=1 / edge_index.size(1),\n",
    "    initialize_node_feature_transformation=initialize_node_feature_transformation,\n",
    ").eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
