{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used for debugging. Should have the same functionality as run_models.py, but with more verbose output.\n",
    "\n",
    "**[TODO]** Update from run_models.py when the dust settles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "# Add the 'scripts' directory to Python Path\n",
    "scripts_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "from training.help_functions import *\n",
    "\n",
    "from gnn.help_functions import (\n",
    "    GNN_Loss,\n",
    "    compute_baseline_of_mean_target,\n",
    "    compute_baseline_of_no_policies,\n",
    ")\n",
    "from gnn.models.point_net_transf_gat import PointNetTransfGAT\n",
    "from gnn.models.eign import EIGNLaplacianConv\n",
    "\n",
    "\n",
    "model = EIGNLaplacianConv(\n",
    "    in_channels_signed= 5,\n",
    "    out_channels_signed= 1,\n",
    "    in_channels_unsigned= 5,\n",
    "    out_channels_unsigned= 1,\n",
    "    hidden_channels_signed=32,\n",
    "    hidden_channels_unsigned=32,\n",
    "    num_blocks=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "\n",
    "# Please adjust as needed\n",
    "dataset_path = os.path.join(\n",
    "    project_root, \"data\", \"test_data\"\n",
    ")\n",
    "base_dir = os.path.join(project_root, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS = [\n",
    "    \"project_name\",\n",
    "    \"predict_mode_stats\",\n",
    "    \"in_channels\",\n",
    "    \"use_all_features\",\n",
    "    \"out_channels\",\n",
    "    \"loss_fct\",\n",
    "    \"use_weighted_loss\",\n",
    "    \"point_net_conv_layer_structure_local_mlp\",\n",
    "    \"point_net_conv_layer_structure_global_mlp\",\n",
    "    \"gat_conv_layer_structure\",\n",
    "    \"use_bootstrapping\",\n",
    "    \"num_epochs\",\n",
    "    \"batch_size\",\n",
    "    \"lr\",\n",
    "    \"early_stopping_patience\",\n",
    "    \"use_dropout\",\n",
    "    \"dropout\",\n",
    "    \"gradient_accumulation_steps\",\n",
    "    \"use_gradient_clipping\",\n",
    "    \"device_nr\",\n",
    "    \"unique_model_description\",\n",
    "    \"use_monte_carlo_dropout\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_parameters(args):\n",
    "\n",
    "    params = {\n",
    "        # KEEP IN MIND: IF WE CHANGE PARAMETERS, WE NEED TO CHANGE THE NAME OF THE RUN IN WANDB (for the config)\n",
    "        \"project_name\": \"eign\",\n",
    "        \"predict_mode_stats\": args.predict_mode_stats,\n",
    "        \"in_channels\": args.in_channels,\n",
    "        \"use_all_features\": args.use_all_features,\n",
    "        \"out_channels\": args.out_channels,\n",
    "        \"loss_fct\": args.loss_fct,\n",
    "        \"use_weighted_loss\": args.use_weighted_loss,\n",
    "        \"point_net_conv_layer_structure_local_mlp\": [\n",
    "            int(x) for x in args.point_net_conv_layer_structure_local_mlp.split(\",\")\n",
    "        ],\n",
    "        \"point_net_conv_layer_structure_global_mlp\": [\n",
    "            int(x) for x in args.point_net_conv_layer_structure_global_mlp.split(\",\")\n",
    "        ],\n",
    "        \"gat_conv_layer_structure\": [\n",
    "            int(x) for x in args.gat_conv_layer_structure.split(\",\")\n",
    "        ],\n",
    "        \"use_bootstrapping\": args.use_bootstrapping,\n",
    "        \"num_epochs\": args.num_epochs,\n",
    "        \"batch_size\": int(args.batch_size),\n",
    "        \"lr\": float(args.lr),\n",
    "        \"early_stopping_patience\": args.early_stopping_patience,\n",
    "        \"use_dropout\": args.use_dropout,\n",
    "        \"dropout\": args.dropout,\n",
    "        \"gradient_accumulation_steps\": args.gradient_accumulation_steps,\n",
    "        \"use_gradient_clipping\": args.use_gradient_clipping,\n",
    "        \"device_nr\": args.device_nr,\n",
    "        \"use_monte_carlo_dropout\": args.use_monte_carlo_dropout,\n",
    "    }\n",
    "\n",
    "    params[\"unique_model_description\"] = \"eign_implementing\"\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch number: 1\n",
      "Processing batch number: 2\n",
      "Loaded 100 items into datalist\n"
     ]
    }
   ],
   "source": [
    "datalist = []\n",
    "batch_num = 1\n",
    "while True and batch_num < 3:  # Change this to \"and batch_num < 10\" for a faster run\n",
    "    print(f\"Processing batch number: {batch_num}\")\n",
    "    # total_memory, available_memory, used_memory = get_memory_info()\n",
    "    # print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "    # print(f\"Available Memory: {available_memory:.2f} GB\")\n",
    "    # print(f\"Used Memory: {used_memory:.2f} GB\")\n",
    "    batch_file = os.path.join(dataset_path, f\"datalist_batch_{batch_num}.pt\")\n",
    "    if not os.path.exists(batch_file):\n",
    "        break\n",
    "    batch_data = torch.load(batch_file, map_location=\"cpu\")\n",
    "    if isinstance(batch_data, list):\n",
    "        datalist.extend(batch_data)\n",
    "    batch_num += 1\n",
    "print(f\"Loaded {len(datalist)} items into datalist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the argparse section with this:\n",
    "args = {\n",
    "    \"in_channels\": 5,\n",
    "    \"use_all_features\": False,\n",
    "    \"out_channels\": 1,\n",
    "    \"loss_fct\": \"mse\",\n",
    "    \"use_weighted_loss\": True,\n",
    "    \"predict_mode_stats\": False,\n",
    "    \"point_net_conv_layer_structure_local_mlp\": \"256\",\n",
    "    \"point_net_conv_layer_structure_global_mlp\": \"512\",\n",
    "    \"gat_conv_layer_structure\": \"128,256,512,256\",\n",
    "    \"use_bootstrapping\": False,\n",
    "    \"num_epochs\": 20,\n",
    "    \"batch_size\": 1,\n",
    "    \"lr\": 0.001,\n",
    "    \"early_stopping_patience\": 5,\n",
    "    \"use_dropout\": True,\n",
    "    \"dropout\": 0.3,\n",
    "    \"gradient_accumulation_steps\": 3,\n",
    "    \"use_gradient_clipping\": True,\n",
    "    \"lr_scheduler_warmup_steps\": 10000,\n",
    "    \"device_nr\": 0,\n",
    "    \"use_monte_carlo_dropout\": True\n",
    "}\n",
    "\n",
    "\n",
    "# Convert the dictionary to an object with attributes\n",
    "class Args:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "\n",
    "\n",
    "args = Args(**args)\n",
    "set_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU 0 with CUDA_VISIBLE_DEVICES=0\n",
      "Starting prepare_data_with_graph_features with 100 items\n",
      "Splitting into subsets...\n",
      "Total dataset length: 100\n",
      "Training subset length: 80\n",
      "Validation subset length: 15\n",
      "Test subset length: 5\n",
      "Split complete. Train: 80, Valid: 15, Test: 5\n",
      "Saving test set...\n",
      "Test set saved to /home/duc-nguyen/Downloads/projects/gnn_predicting_effects_of_traffic_policies/data/eign/eign_implementing/data_created_during_training/test_set.pt\n",
      "Normalizing train set...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00,  5.33it/s]\n",
      "Normalizing x features: 100%|██████████| 1/1 [00:00<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n",
      "Fitting and normalizing pos features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "Normalizing pos features: 100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos features normalized\n",
      "Train set normalized\n",
      "Normalizing validation set...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00, 27.24it/s]\n",
      "Normalizing x features: 100%|██████████| 1/1 [00:00<00:00, 52.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n",
      "Fitting and normalizing pos features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00, 25.13it/s]\n",
      "Normalizing pos features: 100%|██████████| 1/1 [00:00<00:00, 39.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos features normalized\n",
      "Validation set normalized\n",
      "Normalizing test set...\n",
      "Fitting and normalizing x features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00, 69.49it/s]\n",
      "Normalizing x features: 100%|██████████| 1/1 [00:00<00:00, 164.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x features normalized\n",
      "Fitting and normalizing pos features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scaler: 100%|██████████| 1/1 [00:00<00:00, 64.72it/s]\n",
      "Normalizing pos features: 100%|██████████| 1/1 [00:00<00:00, 116.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos features normalized\n",
      "Test set normalized\n",
      "Creating train loader...\n",
      "Train loader created\n",
      "Creating validation loader...\n",
      "Validation loader created\n",
      "Creating test loader...\n",
      "Test loader created\n",
      "Dataloaders and scalers saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthuaduc24042001\u001b[0m (\u001b[33mthuaduc24042001-technical-university-of-munich\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/duc-nguyen/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/training/wandb/run-20250504_165036-gr748lxf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign/runs/gr748lxf' target=\"_blank\">eign_implementing</a></strong> to <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign' target=\"_blank\">https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign/runs/gr748lxf' target=\"_blank\">https://wandb.ai/thuaduc24042001-technical-university-of-munich/eign/runs/gr748lxf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpus = get_available_gpus()\n",
    "best_gpu = select_best_gpu(gpus)\n",
    "set_cuda_visible_device(best_gpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "params = get_parameters(args)\n",
    "\n",
    "# Create directory for the run\n",
    "unique_run_dir = os.path.join(\n",
    "    base_dir, params[\"project_name\"], params[\"unique_model_description\"]\n",
    ")\n",
    "os.makedirs(unique_run_dir, exist_ok=True)\n",
    "\n",
    "model_save_path, path_to_save_dataloader = get_paths(\n",
    "    base_dir=os.path.join(base_dir, params[\"project_name\"]),\n",
    "    unique_model_description=params[\"unique_model_description\"],\n",
    "    model_save_path=\"trained_model/model.pth\",\n",
    ")\n",
    "\n",
    "train_dl, valid_dl, scalers_train, scalers_validation = (\n",
    "    prepare_data_with_graph_features(\n",
    "        datalist=datalist,\n",
    "        batch_size=params[\"batch_size\"],\n",
    "        path_to_save_dataloader=path_to_save_dataloader,\n",
    "        use_all_features=params[\"use_all_features\"],\n",
    "        use_bootstrapping=params[\"use_bootstrapping\"],\n",
    "    )\n",
    ")\n",
    "\n",
    "config = setup_wandb({param: params[param] for param in PARAMETERS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(architecture: str, config: object, device: torch.device):\n",
    "    \"\"\"\n",
    "    Factory function to create the specified model architecture.\n",
    "\n",
    "    Parameters:\n",
    "    - architecture: str, the name of the architecture to use\n",
    "    - config: object containing model parameters\n",
    "    - device: torch device to put the model on\n",
    "\n",
    "    Returns:\n",
    "    - Initialized model on the specified device\n",
    "    \"\"\"\n",
    "    if architecture == \"point_net_transf_gat\":\n",
    "        return PointNetTransfGAT(\n",
    "            in_channels=config.in_channels,\n",
    "            out_channels=config.out_channels,\n",
    "            point_net_conv_layer_structure_local_mlp=config.point_net_conv_layer_structure_local_mlp,\n",
    "            point_net_conv_layer_structure_global_mlp=config.point_net_conv_layer_structure_global_mlp,\n",
    "            gat_conv_layer_structure=config.gat_conv_layer_structure,\n",
    "            use_dropout=config.use_dropout,\n",
    "            dropout=config.dropout,\n",
    "            predict_mode_stats=config.predict_mode_stats,\n",
    "            dtype=torch.float32,\n",
    "        ).to(device)\n",
    "    elif architecture == \"eign\":\n",
    "        return EIGNLaplacianConv(\n",
    "            in_channels_signed=5,\n",
    "            out_channels_signed=1,\n",
    "            in_channels_unsigned=5,\n",
    "            out_channels_unsigned=1,\n",
    "            hidden_channels_signed=32,\n",
    "            hidden_channels_unsigned=32,\n",
    "            num_blocks=4,\n",
    "        ).to(device)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown architecture: {architecture}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline loss mean 21.630630493164062\n",
      "baseline loss no  21.576414108276367\n"
     ]
    }
   ],
   "source": [
    "#gnn_instance = create_model(\"point_net_transf_gat\", config, device)\n",
    "gnn_instance = create_model(\"eign\", config, device)\n",
    "\n",
    "\n",
    "model = gnn_instance.to(device)\n",
    "loss_fct = GNN_Loss(\n",
    "    config.loss_fct, datalist[0].x.shape[0], device, config.use_weighted_loss\n",
    ")\n",
    "\n",
    "baseline_loss_mean_target = compute_baseline_of_mean_target(\n",
    "    dataset=train_dl, loss_fct=loss_fct, device=device, scalers=scalers_train\n",
    ")\n",
    "baseline_loss = compute_baseline_of_no_policies(\n",
    "    dataset=train_dl, loss_fct=loss_fct, device=device, scalers=scalers_train\n",
    ")\n",
    "print(\"baseline loss mean \" + str(baseline_loss_mean_target))\n",
    "print(\"baseline loss no  \" + str(baseline_loss))\n",
    "\n",
    "early_stopping = EarlyStopping(patience=params[\"early_stopping_patience\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this method is being called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/80 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'edge_is_directed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_val_loss, best_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mgnn_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscalers_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalers_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscalers_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalers_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_save_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with validation loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/projects/gnn_predicting_effects_of_traffic_policies/scripts/gnn/models/eign.py:229\u001b[0m, in \u001b[0;36mEIGN.train_model\u001b[0;34m(self, config, loss_fct, optimizer, train_dl, valid_dl, device, early_stopping, model_save_path, scalers_train, scalers_validation)\u001b[0m\n\u001b[1;32m    227\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m train_loss_node_predictions \u001b[38;5;241m+\u001b[39m train_loss_mode_stats\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m         predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x_signed\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mx, x_unsigned\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mx, edge_index\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39medge_index, is_directed\u001b[38;5;241m=\u001b[39m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_is_directed\u001b[49m)\n\u001b[1;32m    230\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m loss_fct(\n\u001b[1;32m    231\u001b[0m             predicted, targets_node_predictions, x_unscaled\n\u001b[1;32m    232\u001b[0m         )\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch_geometric/data/data.py:559\u001b[0m, in \u001b[0;36mData.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_store\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object was created by an older version of PyG. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf this error occurred while loading an already existing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset, remove the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m directory in the dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot folder and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/traffic/lib/python3.10/site-packages/torch_geometric/data/storage.py:96\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'edge_is_directed'"
     ]
    }
   ],
   "source": [
    "best_val_loss, best_epoch = gnn_instance.train_model(\n",
    "    config=config,\n",
    "    loss_fct=loss_fct,\n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=1e-4),\n",
    "    train_dl=train_dl,\n",
    "    valid_dl=valid_dl,\n",
    "    device=device,\n",
    "    early_stopping=early_stopping,\n",
    "    model_save_path=model_save_path,\n",
    "    scalers_train=scalers_train,\n",
    "    scalers_validation=scalers_validation,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Best model saved to {model_save_path} with validation loss: {best_val_loss} at epoch {best_epoch}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
