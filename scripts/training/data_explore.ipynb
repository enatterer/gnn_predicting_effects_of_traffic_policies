{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f29be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 31635], num_nodes=31635, x=[31635, 6], pos=[31635, 3, 2], y=[31635, 1], edge_is_directed=[31635], mode_stats_diff=[6, 3], mode_stats_diff_perc=[6, 3])\n",
      "10\n",
      "<class 'torch_geometric.data.data.Data'>\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "data_list = torch.load(\"../../data/train_data/edge_features2/datalist_batch_1.pt\")\n",
    "print(data_list[0])                     \n",
    "print(len(data_list))\n",
    "\n",
    "# https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Data.html\n",
    "print(type(data_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94f6dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31635, 6])\n",
      "torch.Size([31635, 32])\n",
      "torch.Size([31635, 32])\n",
      "torch.Size([31635, 32])\n",
      "torch.Size([31635, 32])\n",
      "torch.Size([31635, 32])\n",
      "torch.Size([31635, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0877],\n",
       "         [ 0.5377],\n",
       "         [-0.5359],\n",
       "         ...,\n",
       "         [-0.0551],\n",
       "         [ 0.3967],\n",
       "         [ 0.0349]]),\n",
       " tensor([[ 0.3596],\n",
       "         [-2.1780],\n",
       "         [-2.1242],\n",
       "         ...,\n",
       "         [ 1.7848],\n",
       "         [ 0.2460],\n",
       "         [ 0.7414]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Add the 'scripts' directory to Python Path\n",
    "scripts_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "from gnn.models import EIGNLaplacianConv\n",
    "\n",
    "model = EIGNLaplacianConv(\n",
    "    in_channels_signed=6,\n",
    "    out_channels_signed=1,\n",
    "    in_channels_unsigned=6,\n",
    "    out_channels_unsigned=1,\n",
    "    hidden_channels_signed=32,\n",
    "    hidden_channels_unsigned=32,\n",
    "    dtype=torch.float,\n",
    "    num_blocks=4,\n",
    ").eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        x_signed=data_list[0].x,\n",
    "        x_unsigned=None,\n",
    "        edge_index=data_list[0].edge_index,\n",
    "        is_directed=data_list[0].edge_is_directed,\n",
    "    )\n",
    "outputs.signed, outputs.unsigned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57facec",
   "metadata": {},
   "source": [
    "\n",
    "Parameters:\n",
    "    \n",
    "    x (torch.Tensor, optional) – Node feature matrix with shape [num_nodes, num_node_features]. (default: None)\n",
    "\n",
    "    edge_index (LongTensor, optional) – Graph connectivity in COO format with shape [2, num_edges]. (default: None)<>\n",
    "\n",
    "    edge_attr (torch.Tensor, optional) – Edge feature matrix with shape [num_edges, num_edge_features]. (default: None)\n",
    "\n",
    "    y (torch.Tensor, optional) – Graph-level or node-level ground-truth labels with arbitrary shape. (default: None)\n",
    "\n",
    "    pos (torch.Tensor, optional) – Node position matrix with shape [num_nodes, num_dimensions]. (default: None)\n",
    "\n",
    "    time (torch.Tensor, optional) – The timestamps for each event with shape [num_edges] or [num_nodes]. (default: None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8140b82",
   "metadata": {},
   "source": [
    "PyTorch Geometric (PyG) data batches are saved in the `result_path` as `.pt` tensor files. Each sample is a homogenous graph (representing a scenario as decribed above) with the following attributes per node (road segment):\n",
    "- `x`: Node features:\n",
    "    - Volume Base Case\n",
    "    - Capacity Base Case\n",
    "    - Capacity Reduction\n",
    "    - Maximum Speed\n",
    "    - Road Type\n",
    "    - Length\n",
    "    - And additionally, if `use_allowed_modes` is `True`, then booleans indicating whether `Car`, `Bus`, `Public Transport`, `Train`, `Rail`, and `Subway` are allowed on the road segment.\n",
    "- `y`: Target for the GNN, difference in traffic volume between the base case and the simulation run (with policy applied).\n",
    "- `pos`: x and y coordinates of the start, middle, and end of the road segment.\n",
    "\n",
    "And the following attributes for the entire graph:\n",
    "- `edge_index`: Edges of the graph, defined by the start and end nodes of each edge.\n",
    "- `mode_stats_diff`: Difference in travel mode statistics between the base case and the simulation run (with policy applied).\n",
    "- `mode_stats_diff_per`: `mode_stats_diff` in percentage (compared to the base case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the data\n",
    "data_list = torch.load(\"../../data/test_data/datalist_batch_1.pt\")\n",
    "sample = data_list[0]  # Let's examine the first graph\n",
    "\n",
    "# Extract edge_index and node features\n",
    "edge_index = sample.edge_index\n",
    "node_features = sample.x\n",
    "\n",
    "# 1. Compute edge features\n",
    "# Orientation-equivariant features (e.g., traffic volume difference)\n",
    "edge_features_equ = node_features[edge_index[0]] - node_features[edge_index[1]]\n",
    "\n",
    "# Orientation-invariant features (e.g., capacity, speed limit, etc.)\n",
    "edge_features_inv = (node_features[edge_index[0]] + node_features[edge_index[1]]) / 2\n",
    "\n",
    "# 2. Structure edge features into Xequ and Xinv\n",
    "Xequ = edge_features_equ  # Directional edge features\n",
    "Xinv = edge_features_inv  # Non-directional edge features\n",
    "\n",
    "# 3. Handle directed and undirected edges\n",
    "# Aggregate bidirectional edges (u, v) and (v, u) into a single undirected edge\n",
    "directed_edges = edge_index.T.tolist()\n",
    "undirected_edges = set(tuple(sorted(edge)) for edge in directed_edges)\n",
    "undirected_edge_index = torch.tensor(list(undirected_edges)).T\n",
    "\n",
    "# 4. Prepare the transformed data\n",
    "transformed_data = {\n",
    "    \"edge_index\": undirected_edge_index,  # Updated edge index\n",
    "    \"Xequ\": Xequ,  # Orientation-equivariant edge features\n",
    "    \"Xinv\": Xinv,  # Orientation-invariant edge features\n",
    "    \"y_edge\": sample.y  # Edge-level target (if applicable)\n",
    "}\n",
    "\n",
    "# Print the transformed data for verification\n",
    "print(\"=== Transformed Data ===\")\n",
    "print(f\"Edge Index:\\n{transformed_data['edge_index']}\")\n",
    "print(f\"Orientation-Equivariant Features (Xequ):\\n{transformed_data['Xequ']}\")\n",
    "print(f\"Orientation-Invariant Features (Xinv):\\n{transformed_data['Xinv']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
