{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elenanatterer/anaconda3/envs/ml_env/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/elenanatterer/anaconda3/envs/ml_env/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/elenanatterer/anaconda3/envs/ml_env/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <421678CD-1041-32CD-92EF-29D22242240C> /Users/elenanatterer/anaconda3/envs/ml_env/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.transforms import LineGraph\n",
    "from shapely.geometry import LineString\n",
    "import gnn_io as gio\n",
    "\n",
    "from gnn_architectures import GnnMultipleInputFeatures\n",
    "from gnn_architectures import GnnBasic\n",
    "from gnn_architectures import GnnWithPos\n",
    "\n",
    "import gnn_architectures as garch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menatterer\u001b[0m (\u001b[33mtum-traffic-engineering\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "num_epochs = 40\n",
    "batch_size = 20\n",
    "lr = 0.001\n",
    "project_name = 'multiple_features'\n",
    "train_ratio = 0.8\n",
    "wandb.login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the list of dictionaries\n",
    "data_dict_list = torch.load('../data/dataset_1pm_0-1382_with_more_infos.pt')\n",
    "\n",
    "# Reconstruct the Data objects\n",
    "datalist = [Data(x=d['x'], edge_index=d['edge_index'], pos=d['pos'], y=d['y']) for d in data_dict_list]\n",
    "\n",
    "# # Apply normalization to your dataset\n",
    "dataset_normalized = gio.normalize_dataset(datalist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate MSE - baseline error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of y: 0.030937498435378075\n",
      "Standard Deviation of y: 0.074600949883461\n",
      "Baseline error is: 0.005565311759710312\n"
     ]
    }
   ],
   "source": [
    "y_values_normalized = np.concatenate([data.normalized_y for data in dataset_normalized])\n",
    "\n",
    "# Compute the mean and standard deviation\n",
    "mean_y_normalized = np.mean(y_values_normalized)\n",
    "std_y_normalized = np.std(y_values_normalized)\n",
    "\n",
    "print(f\"Mean of y: {mean_y_normalized}\")\n",
    "print(f\"Standard Deviation of y: {std_y_normalized}\")\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "y_values_normalized_tensor = torch.tensor(y_values_normalized, dtype=torch.float32)\n",
    "mean_y_normalized_tensor = torch.tensor(mean_y_normalized, dtype=torch.float32)\n",
    "\n",
    "# Create the target tensor with the same shape as y_values_normalized_tensor\n",
    "target_tensor = mean_y_normalized_tensor * torch.ones_like(y_values_normalized_tensor)\n",
    "\n",
    "# Instantiate the MSELoss function\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "# Compute the MSE \n",
    "mse = mse_loss(y_values_normalized_tensor, target_tensor)\n",
    "\n",
    "# Print the MSE value\n",
    "print(\"Baseline error is: \" + str(mse.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/elenanatterer/Development/GNNs/GNN_predicting_effects_of_traffic_policies/scripts/wandb/run-20240705_152614-mean7kz9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tum-traffic-engineering/multiple_features/runs/mean7kz9' target=\"_blank\">atomic-frost-15</a></strong> to <a href='https://wandb.ai/tum-traffic-engineering/multiple_features' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tum-traffic-engineering/multiple_features' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/multiple_features</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tum-traffic-engineering/multiple_features/runs/mean7kz9' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/multiple_features/runs/mean7kz9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wandb.init(\n",
    "        project=project_name,\n",
    "        config={\n",
    "            \"epochs\": num_epochs,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"lr\": lr,\n",
    "            'early_stopping_patience': 10,\n",
    "            # \"dropout\": 0.15,\n",
    "            })\n",
    "config = wandb.config\n",
    "\n",
    "# gnn_instance = GnnMultipleInputFeatures()\n",
    "gnn_instance = GnnBasic()\n",
    "gnn_instance = GnnWithPos(3, 1)\n",
    "model = gnn_instance.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "loss_fct = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GnnBasic(\n",
       "  (conv1): GCNConv(1, 16)\n",
       "  (conv3): GCNConv(16, 1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset length: 1382\n",
      "Training subset length: 1100\n",
      "Total dataset length: 1382\n",
      "Validation subset length: 260\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "train_dl = gio.create_dataloader(dataset=dataset_normalized, is_train=True, batch_size=config.batch_size, train_ratio=train_ratio)\n",
    "valid_dl = gio.create_dataloader(dataset=dataset_normalized, is_train=False, batch_size=config.batch_size, train_ratio=train_ratio)\n",
    "n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "print(n_steps_per_epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the model\n",
    "\n",
    "We first find a good model for one batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, val_loss: 0.006355380711074059\n",
      "epoch: 1, val_loss: 0.006198488534069979\n",
      "epoch: 2, val_loss: 0.006064380411631786\n",
      "epoch: 3, val_loss: 0.005949619082877269\n",
      "epoch: 4, val_loss: 0.005852257438863699\n",
      "epoch: 5, val_loss: 0.005770632388213506\n",
      "epoch: 6, val_loss: 0.005703596075853476\n",
      "epoch: 7, val_loss: 0.005649861163244798\n",
      "epoch: 8, val_loss: 0.005608262959867716\n",
      "epoch: 9, val_loss: 0.0055776710550372414\n",
      "epoch: 10, val_loss: 0.005556791590956541\n",
      "epoch: 11, val_loss: 0.005544170844726837\n",
      "epoch: 12, val_loss: 0.005538306019913692\n",
      "epoch: 13, val_loss: 0.005537699693097518\n",
      "epoch: 14, val_loss: 0.005540814608908617\n",
      "EarlyStopping counter: 1 out of 5\n",
      "epoch: 15, val_loss: 0.005546100616741639\n",
      "EarlyStopping counter: 2 out of 5\n",
      "epoch: 16, val_loss: 0.005552262246895295\n",
      "EarlyStopping counter: 3 out of 5\n",
      "epoch: 17, val_loss: 0.005558190437463613\n",
      "EarlyStopping counter: 4 out of 5\n",
      "epoch: 18, val_loss: 0.0055630795585994534\n",
      "EarlyStopping counter: 5 out of 5\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>val_loss</td><td>█▇▆▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>val_loss</td><td>0.00556</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">atomic-frost-15</strong> at: <a href='https://wandb.ai/tum-traffic-engineering/multiple_features/runs/mean7kz9' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/multiple_features/runs/mean7kz9</a><br/> View project at: <a href='https://wandb.ai/tum-traffic-engineering/multiple_features' target=\"_blank\">https://wandb.ai/tum-traffic-engineering/multiple_features</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240705_152614-mean7kz9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stopping = gio.EarlyStopping(patience=5, verbose=True)\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    model.train()\n",
    "    data = next(iter(train_dl))\n",
    "    # for idx in range(len(train_dl)):\n",
    "    # for idx, data in enumerate(train_dl):\n",
    "    input_node_features, targets = data.normalized_x.to(device), data.normalized_y.to(device)\n",
    "    predicted = model(data)\n",
    "    train_loss = loss_fct(predicted, targets)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    # wandb.log({\"train_loss\": train_loss.item(), \"epoch\": epoch, \"step\": idx})\n",
    "        # print(f\"epoch: {epoch}, step: {idx}, loss: {train_loss.item()}\")\n",
    "        \n",
    "    val_loss = garch.validate_model_basic(model, valid_dl, loss_fct, device)\n",
    "    wandb.log({\"val_loss\": val_loss})\n",
    "    print(f\"epoch: {epoch}, val_loss: {val_loss}\")\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "    \n",
    "wandb.summary[\"val_loss\"] = val_loss\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Paris_Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
